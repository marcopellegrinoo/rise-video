# -*- coding: utf-8 -*-
"""RISE-st_cineca.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z8437yf9E86nqu0UjznkT-7OtUbg4oJc

### ***Cineca***
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import activations
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.models import load_model
from keras import activations
import numpy as np

"""
##### ***Data & Black-Box***

"""

# IMPORTO I DATI PER VOTTIGNASCO
import os

# Ottieni il percorso effettivo da una variabile d'ambiente
work_path = os.environ['WORK']  # Ottieni il valore della variabile d'ambiente WORK
v_test_OHE_path = os.path.join(work_path, "Water_Resources/rise-video/data/Vottignasco/Vottignasco_00425010001_test_month_OHE.npy")
v_test_image_path = os.path.join(work_path, "Water_Resources/rise-video/data/Vottignasco/Vottignasco_00425010001_test_normalized_image_sequences.npy")
v_test_target_dates_path = os.path.join(work_path, "Water_Resources/rise-video/data/Vottignasco/Vottignasco_00425010001_test_target_dates.npy")

# Carica l'array numpy dai file
vottingasco_test_OHE    = np.load(v_test_OHE_path)
vottignasco_test_image  = np.load(v_test_image_path)
vottignasco_test_dates  = np.load(v_test_target_dates_path)


print(len(vottignasco_test_dates))
print(len(vottignasco_test_image))
print(len(vottingasco_test_OHE))

#print(vottingasco_test_OHE[0], "\n")
#print(vottignasco_test_image[0][0], "\n")

# """##### ***Black Boxes***"""

import os
import tensorflow as tf
from keras.models import load_model

# Se vuoi abilitare il dropout a runtime
mc_dropout = True

# Definizione della classe personalizzata doprout_custom
class doprout_custom(tf.keras.layers.SpatialDropout1D):
    def call(self, inputs, training=None):
        if mc_dropout:
            return super().call(inputs, training=True)
        else:
            return super().call(inputs, training=False)

# Percorso della directory su Cineca
base_dir = os.path.join(os.environ['WORK'], "Water_Resources/rise-video/trained_models/seq2val/Vottignasco")
lstm_suffix = 'time_dist_LSTM'

vott_lstm_models = []

def extract_index(filename):
    """Funzione per estrarre l'indice finale dal nome del file."""
    return int(filename.split('_LSTM_')[-1].split('.')[0])

# Trova tutti i file .keras nella cartella e li aggiunge alla lista
for filename in os.listdir(base_dir):
    if lstm_suffix in filename and filename.endswith(".keras"):
        vott_lstm_models.append(os.path.join(base_dir, filename))

# Ordina i modelli in base all'indice finale
vott_lstm_models = sorted(vott_lstm_models, key=lambda x: extract_index(os.path.basename(x)))

# Lista per i modelli caricati
vott_lstm_models_loaded = []

for i, model_lstm_path in enumerate(vott_lstm_models[:10]):  # Prendo i primi 10 modelli ordinati
    #print(f"Caricamento del modello LSTM {i+1}: {model_lstm_path}")

    # Carico il modello con la classe custom
    model = load_model(model_lstm_path, custom_objects={"doprout_custom": doprout_custom})

    # Aggiungo il modello alla lista
    vott_lstm_models_loaded.append(model)

print(vott_lstm_models_loaded)

"""### ***Import & Drive***"""

!pip install tensorflow==2.15.0 # cuDNN 8.9    CUDA 12.2 # keras 2.15.0

!nvcc --version

!cat /usr/include/cudnn_version.h | grep CUDNN_MAJOR -A 2

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import activations
import sys
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.models import load_model
from keras import activations
import numpy as np

# Commented out IPython magic to ensure Python compatibility.
# Mount Google Drive
from google.colab import drive
drive.mount('/gdrive')
# %cd /gdrive

"""### ***Loading from Google Drive***

##### ***Data***
"""

# Directories

base_path = "./MyDrive/Water_Resources/"
data_path = base_path + "data/training_validation_test_splits"
model_path = base_path + "trained_models/"
modules_path = base_path + "python_modules/"
xai_path = base_path + "XAI/"
results_path = xai_path + "results/"

# IMPORTO I DATI PER VOTTIGNASCO

# Percorso ai file .npy
v_test_OHE_path    = data_path + '/Vottignasco_00425010001_test_month_OHE.npy'
v_test_image_path  = data_path + '/Vottignasco_00425010001_test_normalized_image_sequences.npy'
v_test_target_dates_path = data_path + '/Vottignasco_00425010001_test_target_dates.npy'

# Carica l'array numpy dai file
vottingasco_test_OHE    = np.load(v_test_OHE_path)
vottignasco_test_image  = np.load(v_test_image_path)
vottignasco_test_dates  = np.load(v_test_target_dates_path)

# IMPORTO I DATI PER RACCONIGI

r_test_OHE_path = data_path + '/Racconigi_00417910001_test_month_OHE.npy'
r_test_image_path = data_path + '/Racconigi_00417910001_test_normalized_image_sequences.npy'
r_test_target_dates_path = data_path + '/Racconigi_00417910001_test_target_dates.npy'

# Carica l'array numpy dai file
racconigi_test_OHE    = np.load(r_test_OHE_path)
racconigi_test_image  = np.load(r_test_image_path)
racconigi_test_dates  = np.load(r_test_target_dates_path)

print(len(vottignasco_test_dates))
print(len(vottignasco_test_image))
print(len(vottingasco_test_OHE))

print(len(racconigi_test_dates))
print(len(racconigi_test_image))
print(len(racconigi_test_OHE))

print(vottingasco_test_OHE[0], "\n")
print(vottignasco_test_image[0][0], "\n")

"""##### ***Black Boxes***"""

from keras.models import load_model

# If you want to load the entire model, dropout_custom layer has to be defined:

mc_dropout = True

# Definizione della classe personalizzata doprout_custom
class doprout_custom(tf.keras.layers.SpatialDropout1D):
    def call(self, inputs, training=None):
        if mc_dropout:
            return super().call(inputs, training=True)
        else:
            return super().call(inputs, training=False)

# Trovo i path dei modelli dell'ensemble nel mio drive. Poi li ordino in base al nr del modello.
# VOTTIGNASCO

import os

base_dir = base_dir = model_path + "seq2val/Vottignasco"
lstm_suffix = 'time_dist_LSTM'

vott_lstm_models = []
vott_lstm_weights = []


def extract_index(filename):
    """Funzione per estrarre l'indice finale dal nome del file."""
    return int(filename.split('_')[-1].split('.')[0])

# Trova tutti i file e li aggiunge alle rispettive liste
for root, _, files in os.walk(base_dir):
    for filename in files:
        full_path = os.path.join(root, filename)
        if lstm_suffix in filename:
            if filename.endswith(".keras"):
              vott_lstm_models.append(full_path)
            else:
              vott_lstm_weights.append(full_path)

# Ordina i modelli in base all'indice finale
vott_lstm_models = sorted(vott_lstm_models, key=lambda x: extract_index(os.path.basename(x)))
vott_lstm_weights = sorted(vott_lstm_weights, key=lambda x: extract_index(os.path.basename(x)))

# Trovo i path dei modelli dell'ensemble nel mio drive. Poi li ordino in base al nr del modello.
# RACCONIGI

import os

base_dir = base_dir = model_path + "seq2val/Racconigi"
lstm_suffix = 'time_dist_LSTM'

racc_lstm_models = []
racc_lstm_weights = []


def extract_index(filename):
    """Funzione per estrarre l'indice finale dal nome del file."""
    return int(filename.split('_')[-1].split('.')[0])

# Trova tutti i file e li aggiunge alle rispettive liste
for root, _, files in os.walk(base_dir):
    for filename in files:
        full_path = os.path.join(root, filename)
        if lstm_suffix in filename:
            if filename.endswith(".keras"):
              racc_lstm_models.append(full_path)
            else:
              racc_lstm_weights.append(full_path)

# Ordina i modelli in base all'indice finale
racc_lstm_models = sorted(racc_lstm_models, key=lambda x: extract_index(os.path.basename(x)))
racc_lstm_weights = sorted(racc_lstm_weights, key=lambda x: extract_index(os.path.basename(x)))

# Lista dei path dei modelli e dei pesi
vott_lstm_models_loaded = []
racc_lstm_models_loaded = []

for i in range(10):
    print(f"Caricamento dei modelli LSTM {i+1}")

    # VOTTIGNASCO
    model_lstm_path = vott_lstm_models[i]
    # Carico il modello CNN+LSTM
    model = load_model(model_lstm_path, custom_objects={"doprout_custom": doprout_custom})
    # Aggiungo il modello alla lista
    vott_lstm_models_loaded.append(model)

    # RACCONIGI
    #racc_model_path_i = racc_lstm_models[i]
    #racc_model = load_model(racc_model_path_i, custom_objects={"doprout_custom": doprout_custom})
    #racc_lstm_models_loaded.append(racc_model)

vott_lstm_models_loaded

racc_lstm_models_loaded

"""### ***RISE-st***

#### ***Generation Masks (3D): Uniform***
"""

# Masks Geeneration

from scipy.interpolate import RegularGridInterpolator

# Funzione per eseguire l'upsampling usando RegularGridInterpolator
def upsample_mask(mask, target_shape):
    # Crea la griglia di origine e destinazione
    original_shape = mask.shape
    x = np.linspace(0, original_shape[0] - 1, original_shape[0])
    y = np.linspace(0, original_shape[1] - 1, original_shape[1])
    z = np.linspace(0, original_shape[2] - 1, original_shape[2])

    # Crea una griglia per la destinazione (dimensione finale)
    target_x = np.linspace(0, original_shape[0] - 1, target_shape[0])
    target_y = np.linspace(0, original_shape[1] - 1, target_shape[1])
    target_z = np.linspace(0, original_shape[2] - 1, target_shape[2])

    # Crea l'interpolatore
    interpolator = RegularGridInterpolator((x, y, z), mask, method='linear', bounds_error=False, fill_value=0)

    # Costruisci la griglia di destinazione e ottieni i nuovi valori
    target_coords = np.array(np.meshgrid(target_x, target_y, target_z, indexing='ij')).reshape(3, -1).T
    upsampled_mask = interpolator(target_coords)

    # Ristruttura l'array in base alla forma finale
    return upsampled_mask.reshape(target_shape)

def random_crop(mask, crop_size):
    max_shift_h = mask.shape[0] - crop_size[0]
    max_shift_w = mask.shape[1] - crop_size[1]
    max_shift_d = mask.shape[2] - crop_size[2]

    shift_h = np.random.randint(0, max_shift_h + 1)
    shift_w = np.random.randint(0, max_shift_w + 1)
    shift_d = np.random.randint(0, max_shift_d + 1)

    return mask[shift_h:shift_h + crop_size[0],
                shift_w:shift_w + crop_size[1],
                shift_d:shift_d + crop_size[2]]

import random

def generate_rise_masks_3d(N, H, W, D, h, w, d, p):
  # Step 1: Creazione maschere binarie più piccole
  masks = np.random.rand(N, h, w, d) < p  # Maschere di dimensione (N, h, w, d) binarie
  # Step 2: Upsampling delle maschere
  upsampled_masks = np.array([upsample_mask(mask, (H, W, D)) for mask in masks])
  # Step 3: Cropping e traslazione casuale
  cropped_masks = np.array([random_crop(mask, (H, W, D)) for mask in upsampled_masks])

  beta = random.choice([-1.0, +1.0])

  masks = cropped_masks * beta

  return masks

# Parametri
H, W, D = 104, 5, 8  # Dimensione dei frame (104 frame 5x8)
h, w, d = 8, 2, 4    # Dimensione maschera più piccola
N = 10000               # Numero di maschere
p = 0.2              # Probabilità di un pixel attivo

# Step 1: Creazione maschere binarie più piccole
masks = generate_rise_masks_3d(N, H, W, D, h, w, d, p)

import matplotlib.pyplot as plt

tmp_mask = masks[0]
print(np.max(tmp_mask))

if (np.sum(tmp_mask) > 0):
  vmin, vmax = 0.0, +1.0
else:
  vmin, vmax = -1.0, 0.0

for t,frame in enumerate(tmp_mask):
  plt.imshow(frame, origin='lower', vmin=vmin, vmax=vmax)
  plt.title(f'Noise at time step {t}')
  plt.colorbar()
  plt.show()

import copy

# Somma ad ogni time-step la maschera generata sul canale specificato

def perturb_instance(instance, masks, channel):
    masked = []

    # Itero su tutte le N maschere generate
    for mask in masks:
        masked_images = copy.deepcopy(instance)  # Copia profonda delle immagini originali

        # Perturba solo il canale specificato
        masked_images[..., channel] = np.add(
            masked_images[..., channel],
            mask )

        masked.append(masked_images)

    return masked

"""#### ***Prediction with Black-Box***"""

import tensorflow as tf

def ensemble_predict(models, images, x3_exp):
    # Se images è una lista, calcoliamo la lunghezza
    if isinstance(images, list):
        len_x3 = len(images)
    else:
        len_x3 = 1
        images = [images]  # Rendi images una lista con un solo elemento

    # Conversione in tensori
    Y_test = tf.stack([tf.convert_to_tensor(img, dtype=tf.float32) for img in images])
    Y_test_x3 = tf.tile(tf.expand_dims(tf.convert_to_tensor(x3_exp, dtype=tf.float32), axis=0), [len_x3, 1, 1])

    # Inizializza una lista per raccogliere le predizioni
    all_preds = []

    # Itera attraverso i modelli e raccogli le predizioni
    for model in models:
        preds = model.predict([Y_test, Y_test_x3], verbose=0)
        all_preds.append(preds)

    # Converte la lista di predizioni in un tensore di TensorFlow
    all_preds_tensor = tf.stack(all_preds)

    # Calcola la media lungo l'asse dei modelli (asse 0)
    mean_preds = tf.reduce_mean(all_preds_tensor, axis=0)

    return mean_preds.numpy()

"""#### ***Saliency Video***"""

def calculate_saliency_map(preds_array, masks):
    """
    Calcola la mappa di salienza media data una serie di predizioni e maschere.

    :param preds_array: Array di predizioni (numero di maschere x dimensioni predizione).
    :param masks: Array di maschere (numero di maschere x dimensioni maschera).
    :return: Mappa di salienza media.
    """
    sal = []
    for j in range(len(masks)):
        sal_i = preds_array[j] * np.abs(masks[j])
        sal.append(sal_i.reshape(-1, 5, 8))  # Adatta la shape secondo il formato orginiale dei frame

    # Rimuovere le dimensioni extra per fare np.mean lungo axis=0. masks ha shape (N,5,8,1)
    masks_squeezed = np.squeeze(np.abs(masks))
    # Ora calcola la media lungo l'asse 0
    ev_masks = np.mean(masks_squeezed, axis=0)

    sal = (1/ev_masks) * np.mean(sal, axis=0)

    return sal

"""#### ***Plot Season-Mean for Saliency-Vector***

"""

vottignasco_test_images_dates = np.load(data_path + '/Vottignasco_00425010001_test_image_sequences_dates.npy')

# Calcolo del valore medio di Salinecy per stagione per ogni istanza di Vottignasco

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd


def get_index_range_for_season(seasons):
  indices_range_season = []  # sarà istanziata con triplette (start_index, end_index, season) per ogni stagione

  season_prev = seasons[0]  # Inizializzo con la prima stagione al time-step 0
  start_index = 0

  for i, season in enumerate(seasons):
    if (season != season_prev):
      #print("Ok è cambiata la stagione al time-step", i)
      indices_range_season.append((start_index, i-1, season_prev))
      season_prev = season
      start_index = i

    # Caso in cui negli ultimi time step ho una stagione differente!
    if (i==103):
      last_triple = indices_range_season[-1:]
      if (last_triple[0][2] != season_prev):
        indices_range_season.append((last_triple[0][1] + 1, 103, seasons[103]))

  return indices_range_season

def get_season(day):
  spring = np.arange(80, 172)
  summer = np.arange(172, 264)
  fall = np.arange(264, 355)

  if day in spring:
    season = 'Spring'
  elif day in summer:
    season = 'Summer'
  elif day in fall:
    season = 'Autumn'
  else:
    season = 'Winter'

  return season

def plot_sv_mean_per_season(sv_nr_instance, nr_instance):
  date_target = vottignasco_test_dates[nr_instance].astype('datetime64[D]')

  x1_i = copy.deepcopy(vottignasco_test_image[nr_instance])
  x1_i_dates = copy.deepcopy(vottignasco_test_images_dates[nr_instance])

  dates = pd.to_datetime(x1_i_dates)

  tm_days = [date.timetuple().tm_yday for date in dates]
  seasons = [get_season(tm_yday) for tm_yday in tm_days]

  # Ottieni le triplette (indice_iniziale, indice_finale, stagione)
  indices_range_season = get_index_range_for_season(seasons)

  # Nel caso di 9 stagioni creo un griglia 3x4, altrimenti 2x4
  if len(indices_range_season) == 9:
    # Imposta i plot in una griglia 3x4
    fig, axes = plt.subplots(3, 4, figsize=(15, 14))
  else:
    fig, axes = plt.subplots(2, 4, figsize=(15, 14))
  axes = axes.flatten()  # Converti la matrice di subplot in una lista

  # Trova i valori minimo e massimo per la colorbar
  vmin = np.min(sv_nr_instance)
  vmax = np.max(sv_nr_instance)

  for i, (index_start, index_end, season) in enumerate(indices_range_season):
      if index_start == index_end:
          sv_mean_season = sv_nr_instance[index_start]
      else:
          sv_mean_season = np.mean(sv_nr_instance[index_start:index_end], axis=0)

      im = axes[i].imshow(sv_mean_season, cmap='Reds', vmin=vmin, vmax=vmax, origin='lower')
      year = x1_i_dates[index_end].astype('datetime64[Y]').astype(int) + 1970
      axes[i].set_title(f'Mean Saliency-Video - {season}, {year}', fontdict={'fontsize': 10})
      x_ticks = np.arange(0, 8, step=1)  # crea tick ogni 1
      axes[i].set_xticks(x_ticks)

  # Disattiva gli assi vuoti
  for j in range(i + 1, len(axes)):
      axes[j].axis('off')

  # Riduci lo spazio bianco tra i subplot
  plt.tight_layout()

  if len(indices_range_season) == 9:
    # Aggiusta i margini e riduci ulteriormente hspace e wspace per avvicinare i subplot
    fig.subplots_adjust(left=0.05, right=0.85, top=0.92, bottom=0.40, hspace=0.12, wspace=0.12)
    # Aggiungi la colorbar a destra dei subplot
    cbar = fig.colorbar(im, ax=axes, orientation='vertical', fraction=0.02, pad=0.05, use_gridspec=True, aspect=25)
  else:
    fig.subplots_adjust(left=0.05, right=0.85, top=0.92, bottom=0.60, hspace=0.15, wspace=0.15)
    cbar = fig.colorbar(im, ax=axes, orientation='vertical', fraction=0.02, pad=0.05, use_gridspec=True, aspect=16)

  cbar.set_label('Saliency', fontsize=11)

  # Titolo principale
  fig.suptitle(f'Mean Saliency-Video per Season on instance no. {nr_instance}, Date: {date_target}', fontsize=16)

  # Salva la figura con dpi=400
  #plt.savefig(f'/content/sv_per_season_vott_norm_{nr_instance}.png', dpi=400, bbox_inches='tight')
  #plt.savefig(f'./MyDrive/Water_Resources/results/spatial-temporal/sv_mean_per_season/sv_per_season_vott_norm_{nr_instance}.png', dpi=400, bbox_inches='tight')

  plt.show()
  plt.close(fig)

"""#### ***Spatial-Temporal RISE: Algorithm***"""

def rise_spatial_temporal_explain(nr_instance, data_test_image, data_test_OHE, models, channel,
                                  p, H, W, D, h, w, d, N):

  #print(f"############### RISE-Spatial con h,w=({h},{w}), p={p} e N={N} ############################")

  instance    = copy.deepcopy(data_test_image[nr_instance])  # istanza da spiegare
  x3_instance = copy.deepcopy(data_test_OHE[nr_instance])    # One-Hot encode mesi dei frame dell'istanza

  masks = generate_rise_masks_3d(N, H, W, D, h, w, d, p)
  perturbed_instances = perturb_instance(instance, masks, channel)

  # Predizione originale
  pred_original = ensemble_predict(models, instance, x3_instance)
  # Predizioni su istanze perturbate
  preds_masked = ensemble_predict(models, perturbed_instances, x3_instance)

  # Differenza tra predizione originale e perturbata
  diff_pred = [abs(pred_original - pred_masked) for pred_masked in preds_masked]
  weights_array = np.concatenate(diff_pred, axis=0)

  saliency_video_i = calculate_saliency_map(weights_array, masks)

  return saliency_video_i

"""### ***Experiments***"""

from tqdm import tqdm

models = vott_lstm_models_loaded
channel_prec = 0

# Parametri
H, W, D = 104, 5, 8  # Dimensione dei frame (104 frame 5x8)
h, w, d = 8, 2, 4    # Dimensione maschera più piccola
N = 15000               # Numero di maschere
p = 0.2              # Probabilità di un pixel attivo

saliency_video_vott_test = []

for nr_instance, _ in enumerate(vottignasco_test_image):
  print(f"################### RISE-Spatial-Temporal Explanation for Vottingasco Test Instance nr {nr_instance} ##################################")

  saliency_video_i = rise_spatial_temporal_explain(nr_instance, vottignasco_test_image, vottingasco_test_OHE, models, channel_prec,
                                                   p, H, W, D, h, w, d, N)

  saliency_video_vott_test.append(saliency_video_i)

  break

  print("######################################################################################## \n")

saliency_video_vott_test[0].shape

plot_sv_mean_per_season(saliency_video_vott_test[0], 0)