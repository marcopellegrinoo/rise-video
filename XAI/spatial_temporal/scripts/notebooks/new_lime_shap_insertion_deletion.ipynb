{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 17:46:06.729510: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-05 17:46:09.194569: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-05 17:46:17.026225: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-05 17:46:17.030177: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-05 17:46:17.856718: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-05 17:46:21.531601: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-05 17:46:21.656047: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-05 17:46:47.459114: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"lime_shap_st_multiplicative_norm_zero.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1Rjw096Slt1atIGGrFC_G3wU8ivBfmIoF\n",
    "\n",
    "### ***Cineca***\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras import activations\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from keras.models import load_model\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "import pickle\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import xarray\n",
    "import rioxarray\n",
    "from skimage.segmentation import slic\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "105\n",
      "105\n",
      "[<keras.src.engine.functional.Functional object at 0x7fb86b4ed690>, <keras.src.engine.functional.Functional object at 0x7fb86adfcc10>, <keras.src.engine.functional.Functional object at 0x7fb86abcf790>, <keras.src.engine.functional.Functional object at 0x7fb86ac62cb0>, <keras.src.engine.functional.Functional object at 0x7fb86aacf910>, <keras.src.engine.functional.Functional object at 0x7fb86ab91300>, <keras.src.engine.functional.Functional object at 0x7fb86aa2e020>, <keras.src.engine.functional.Functional object at 0x7fb86aa92bf0>, <keras.src.engine.functional.Functional object at 0x7fb86a9278b0>, <keras.src.engine.functional.Functional object at 0x7fb86a7abe80>]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# IMPORTO I DATI PER VOTTIGNASCO\n",
    "import os\n",
    "\n",
    "# Ottieni il percorso effettivo da una variabile d'ambiente\n",
    "work_path = os.environ['WORK']  # Ottieni il valore della variabile d'ambiente WORK\n",
    "v_test_OHE_path = os.path.join(work_path, \"Water_Resources/rise-video/data/Vottignasco/Vottignasco_00425010001_test_month_OHE.npy\")\n",
    "v_test_image_path = os.path.join(work_path, \"Water_Resources/rise-video/data/Vottignasco/Vottignasco_00425010001_test_normalized_image_sequences.npy\")\n",
    "v_test_target_dates_path = os.path.join(work_path, \"Water_Resources/rise-video/data/Vottignasco/Vottignasco_00425010001_test_target_dates.npy\")\n",
    "v_test_images_dates_path = os.path.join(work_path, \"Water_Resources/rise-video/data/Vottignasco/Vottignasco_00425010001_test_image_sequences_dates.npy\")\n",
    "shapefile_path = os.path.join(work_path, \"Water_Resources/rise-video/data/Vottignasco/shapefile_raster/\")\n",
    "\n",
    "# Carica l'array numpy dai file\n",
    "vottignasco_test_OHE    = np.load(v_test_OHE_path)\n",
    "vottignasco_test_image  = np.load(v_test_image_path)\n",
    "vottignasco_test_dates  = np.load(v_test_target_dates_path)\n",
    "vottignasco_test_images_dates = np.load(v_test_images_dates_path)\n",
    "\n",
    "print(len(vottignasco_test_dates))\n",
    "print(len(vottignasco_test_image))\n",
    "print(len(vottignasco_test_OHE))\n",
    "\n",
    "\n",
    "# \"\"\"##### ***Black Boxes***\"\"\"\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "\n",
    "# Se vuoi abilitare il dropout a runtime\n",
    "mc_dropout = True\n",
    "\n",
    "# Definizione della classe personalizzata doprout_custom\n",
    "class doprout_custom(tf.keras.layers.SpatialDropout1D):\n",
    "    def call(self, inputs, training=None):\n",
    "        if mc_dropout:\n",
    "            return super().call(inputs, training=True)\n",
    "        else:\n",
    "            return super().call(inputs, training=False)\n",
    "\n",
    "# Percorso della directory su Cineca\n",
    "base_dir = os.path.join(os.environ['WORK'], \"Water_Resources/rise-video/trained_models/seq2val/Vottignasco\")\n",
    "lstm_suffix = 'time_dist_LSTM'\n",
    "\n",
    "vott_lstm_models = []\n",
    "\n",
    "def extract_index(filename):\n",
    "    \"\"\"Funzione per estrarre l'indice finale dal nome del file.\"\"\"\n",
    "    return int(filename.split('_LSTM_')[-1].split('.')[0])\n",
    "\n",
    "# Trova tutti i file .keras nella cartella e li aggiunge alla lista\n",
    "for filename in os.listdir(base_dir):\n",
    "    if lstm_suffix in filename and filename.endswith(\".keras\"):\n",
    "        vott_lstm_models.append(os.path.join(base_dir, filename))\n",
    "\n",
    "# Ordina i modelli in base all'indice finale\n",
    "vott_lstm_models = sorted(vott_lstm_models, key=lambda x: extract_index(os.path.basename(x)))\n",
    "\n",
    "# Lista per i modelli caricati\n",
    "vott_lstm_models_loaded = []\n",
    "\n",
    "for i, model_lstm_path in enumerate(vott_lstm_models[:10]):  # Prendo i primi 10 modelli ordinati\n",
    "    #print(f\"Caricamento del modello LSTM {i+1}: {model_lstm_path}\")\n",
    "\n",
    "    # Carico il modello con la classe custom\n",
    "    model = load_model(model_lstm_path, custom_objects={\"doprout_custom\": doprout_custom})\n",
    "\n",
    "    # Aggiungo il modello alla lista\n",
    "    vott_lstm_models_loaded.append(model)\n",
    "\n",
    "print(vott_lstm_models_loaded)\n",
    "\n",
    "\n",
    "\"\"\"#### ***Application Masks***\"\"\"\n",
    "\n",
    "def multiplicative_uniform_noise_onechannel(instance, zs_primes, masks, channel, std_zero_value=-0.6486319166678826):\n",
    "  \"\"\"\n",
    "  param:masks: maschere generate per ogni superpixel\n",
    "  \"\"\"\n",
    "  masked = []\n",
    "  for z in zs_primes:\n",
    "    masked_instance = copy.deepcopy(instance)\n",
    "    for i,z_i in enumerate(z):\n",
    "      if z_i == 0:\n",
    "         # Applica la perturbazione solo al canale specificato\n",
    "        masked_instance[..., channel] = (\n",
    "            masked_instance[..., channel] * masks[i] + (1 - masks[i]) * std_zero_value)\n",
    "\n",
    "    masked.append(masked_instance)\n",
    "\n",
    "  return masked\n",
    "\n",
    "\"\"\"#### ***Predizione sulle Istanze Perturbate***\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def ensemble_predict(models, images, x3_exp, batch_size=1000):\n",
    "    # Assicuriamoci che images sia una lista\n",
    "    if not isinstance(images, list):\n",
    "        images = [images]\n",
    "\n",
    "    len_x3 = len(images)\n",
    "\n",
    "    # Convertiamo x3_exp in un tensore replicato per ogni immagine\n",
    "    x3_exp_tensor = tf.convert_to_tensor(x3_exp, dtype=tf.float32)\n",
    "\n",
    "    # Lista per raccogliere le predizioni finali\n",
    "    final_preds = []\n",
    "\n",
    "    # Processamento a batch\n",
    "    for i in range(0, len_x3, batch_size):\n",
    "        batch_images = images[i:i + batch_size]\n",
    "        batch_len = len(batch_images)\n",
    "\n",
    "        # Conversione batch in tensori\n",
    "        Y_test = tf.stack([tf.convert_to_tensor(img, dtype=tf.float32) for img in batch_images])\n",
    "        Y_test_x3 = tf.tile(tf.expand_dims(x3_exp_tensor, axis=0), [batch_len, 1, 1])\n",
    "\n",
    "        # Raccoglie le predizioni di tutti i modelli per il batch corrente\n",
    "        batch_preds = []\n",
    "\n",
    "        for model in models:\n",
    "            preds = model.predict([Y_test, Y_test_x3], verbose=0)\n",
    "            batch_preds.append(preds)\n",
    "\n",
    "        # Converte le predizioni del batch in un tensore e calcola la media\n",
    "        batch_preds_tensor = tf.stack(batch_preds)\n",
    "        mean_batch_preds = tf.reduce_mean(batch_preds_tensor, axis=0)\n",
    "\n",
    "        # Aggiunge le predizioni del batch alla lista finale\n",
    "        final_preds.extend(mean_batch_preds.numpy())\n",
    "\n",
    "    return np.array(final_preds)\n",
    "\n",
    "\"\"\"###### ***Spatial-Superpixels***\"\"\"\n",
    "\n",
    "import geopandas as gpd\n",
    "import xarray\n",
    "import rioxarray\n",
    "from skimage.segmentation import slic\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_spatial_superpixels(shapefile_path, n_segments=8, compactness=15):\n",
    "  # DTM [50m] import\n",
    "  dtm_piemonte = rioxarray.open_rasterio(shapefile_path + 'DTMPiemonte_filled_50m.tif')\n",
    "  dtm_piemonte = dtm_piemonte.rio.reproject(\"epsg:4326\")\n",
    "  dtm_piemonte = dtm_piemonte.where(dtm_piemonte != -99999) # Take valid pixel\n",
    "\n",
    "  # Catchment shapefile\n",
    "  catchment = gpd.read_file(shapefile_path + \"BAC_01_bacialti.shp\") # select GRANA-MAIRA\tand VARAITA\n",
    "  catchment = catchment.to_crs('epsg:4326')\n",
    "\n",
    "  # Select only the Grana-Maira catchment\n",
    "  catchment_GM = catchment.loc[catchment.NOME == \"GRANA-MAIRA\"]\n",
    "  catchment_GM = catchment_GM.reset_index(drop = True)\n",
    "\n",
    "  # Retrieve the borders of the catchment from the shapefile\n",
    "  xmin_clip, ymin_clip, xmax_clip, ymax_clip = catchment_GM.total_bounds\n",
    "  # Extend the borders to include more pixel on the borders\n",
    "\n",
    "  increase = 0.05 # Degrees\n",
    "  #ymin_clip -= increase # not needed\n",
    "  xmin_clip += increase # \"+\" for subset for pixel included in the mask\n",
    "  xmax_clip += increase\n",
    "  #ymax_clip += increase # not needed\n",
    "\n",
    "  dtm_piemonte_clipped = dtm_piemonte.rio.clip_box( minx = xmin_clip, maxx= xmax_clip , miny= ymin_clip , maxy= ymax_clip)\n",
    "\n",
    "  # Creazione img 5x8 cone lat,lon,dtm\n",
    "  # Definizione delle coordinate\n",
    "  lon = np.array([6.938, 7.063, 7.188, 7.313, 7.438, 7.563, 7.688, 7.813])  # 8 valori\n",
    "  lat = np.array([44.313, 44.438, 44.563, 44.688, 44.813])  # 5 valori\n",
    "\n",
    "  # Creazione di una griglia lat-lon 5x8\n",
    "  lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
    "\n",
    "  # Creazione di un array 5x8x3\n",
    "  img = np.zeros((5, 8, 3))\n",
    "\n",
    "  # Assegno le coordinate nei primi due canali\n",
    "  img[:, :, 0] = lat_grid  # Canale 0 = latitudine\n",
    "  img[:, :, 1] = lon_grid  # Canale 1 = longitudine\n",
    "  img[:, :, 2] = 0  # Canale 2 = valore placeholder\n",
    "\n",
    "  for nr_lat,latitude in enumerate(lat):\n",
    "    for  nr_lon,longitude in enumerate(lon):\n",
    "      img[nr_lat, nr_lon, 2] = dtm_piemonte_clipped.sel(x=longitude, y=latitude, method='nearest').values\n",
    "\n",
    "  img = np.nan_to_num(img, nan=0.0)\n",
    "\n",
    "  # SLIC\n",
    "  segments = slic(img, n_segments=n_segments, compactness=compactness)\n",
    "\n",
    "  # Creazione Spatial-Superpixels\n",
    "  # Trova i valori unici nella matrice (i cluster)\n",
    "  clusters = np.unique(segments)\n",
    "\n",
    "  # Creazione di una lista di matrici binarie per ogni cluster\n",
    "  binary_matrices = {}\n",
    "\n",
    "  for cluster in clusters:\n",
    "      binary_matrices[cluster] = (segments == cluster).astype(int)\n",
    "\n",
    "  spatial_superpixels = [matrix for _, matrix in binary_matrices.items()]\n",
    "\n",
    "  spatial_superpixel_clusters = []\n",
    "\n",
    "  for ss in spatial_superpixels:\n",
    "    indices = np.argwhere(ss == 1)\n",
    "    cluster_pixels = [(x, y) for x, y in indices]\n",
    "    spatial_superpixel_clusters.append(cluster_pixels)\n",
    "\n",
    "  return spatial_superpixels, spatial_superpixel_clusters, segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"#### ***Evaluation Metrics***\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def calculate_auc(x, y):\n",
    "    \"\"\"\n",
    "    Calcola l'area sotto la curva (AUC) utilizzando il metodo del trapezio.\n",
    "\n",
    "    :param x: Valori dell'asse x (frazione dei pixel/frame inseriti).\n",
    "    :param y: Valori dell'asse y (errori calcolati).\n",
    "    :return: Area sotto la curva.\n",
    "    \"\"\"\n",
    "    return np.trapz(y, x)\n",
    "\n",
    "def calculate_auc_and_mean_errors(errors_all_dateset):\n",
    "  mean_errors = np.mean(errors_all_dateset, axis=0)\n",
    "  # Array x per il numero di superpixel inseriti\n",
    "  x = np.arange(0, len(mean_errors))  # Array dinamico basato sulla lunghezza dei dati\n",
    "  auc = calculate_auc(x, mean_errors)\n",
    "\n",
    "  return auc,mean_errors\n",
    "\n",
    "\"\"\"##### ***Insertion***\"\"\"\n",
    "\n",
    "def update_instance_with_superpixels(current_instance, original_instance, start, end, list_of_pixel):\n",
    "    \"\"\"\n",
    "    Aggiorna l'immagine inserendo i pixel più importanti.\n",
    "\n",
    "    :param current_instance: Istanza corrente.\n",
    "    :param original_instance: Istanza originale.\n",
    "    :param index_of_superpixels: Lista contente gli indici del superpixel considerato\n",
    "    :return: Istanza aggiornata con il superpixel.\n",
    "    \"\"\"\n",
    "    new_current_instance = current_instance.copy()\n",
    "\n",
    "    for x,y in list_of_pixel:\n",
    "      for t in range(start,end):\n",
    "        new_current_instance[t, x, y, :] = original_instance[t, x, y, :]\n",
    "    return new_current_instance\n",
    "\n",
    "def insertion(models, original_instance, x3, sorted_per_importance_all_superpixels_index, initial_blurred_instance, original_prediction):\n",
    "    \"\"\"\n",
    "    Calcola la metrica di inserimento per una spiegazione data.\n",
    "\n",
    "    :param models: Lista di modelli pre-addestrati.\n",
    "    :param original_instance: Istanza originale.\n",
    "    :param x3: Codifica one-hot per la previsione.\n",
    "    :param sorted_per_importance_all_superpixels_index: Lista di liste di tutti i superpixel per importanza\n",
    "    :param initial_blurred_images: Immagine iniziale con tutti i pixel a zero.\n",
    "    :return: Lista degli errori ad ogni passo di inserimento.\n",
    "    \"\"\"\n",
    "\n",
    "    # Lista per memorizzare le istanze a cui aggiungo pixel mano a mano. Inizializzata con istanza iniziale blurrata\n",
    "    insertion_images = [initial_blurred_instance]\n",
    "\n",
    "    # Predizione sull'immagine iniziale (tutti i pixel a zero)\n",
    "    I_prime = copy.deepcopy(initial_blurred_instance)\n",
    "\n",
    "    # Aggiungere gradualmente i pixel (per ogni frame) più importanti. Ottengo una lista con tutte le img con i pixel aggiunti in maniera graduale\n",
    "    for start,end,list_of_pixel in sorted_per_importance_all_superpixels_index:\n",
    "        I_prime = update_instance_with_superpixels(I_prime, original_instance, start,end,list_of_pixel)\n",
    "        insertion_images.append(I_prime)\n",
    "\n",
    "    # Calcolo le predizioni sulle istanze a cui ho aggiunto i pixel in maniera graduale\n",
    "    new_predictions = ensemble_predict(models, insertion_images, x3)\n",
    "    # Rispetto ad ogni suddetta predizione, calcolo il MSE rispetto la pred sull'istanza originaria (come da test-set). Ignora la prima che è sull'img blurrata originale\n",
    "    errors = [mean_squared_error(original_prediction, masked_pred) for masked_pred in new_predictions[1:]]\n",
    "\n",
    "    initial_error = mean_squared_error(original_prediction, new_predictions[0])\n",
    "    print(f\"Initial Prediction with Blurred Instance, new prediction: {new_predictions[0]}, error: {initial_error}\")\n",
    "    only_inserted_pixel_new_predictions = new_predictions[1:]\n",
    "\n",
    "    for nr_superpixel, error in enumerate(errors):\n",
    "      print(f\"SuperPixel: {sorted_per_importance_all_superpixels_index[nr_superpixel]}, new prediction: {only_inserted_pixel_new_predictions[nr_superpixel]}, error: {error}\")\n",
    "\n",
    "    total_errors = [initial_error] + errors # Errore iniziale + errori su tutti i pixel inseriti\n",
    "\n",
    "    # Nuovo asse X: numero di superpixel inseriti (1, 2, ..., 8)\n",
    "    x = np.arange(0, len(total_errors))  # Da 0 a 8 inclusi\n",
    "    #print(x)\n",
    "\n",
    "    x_for_auc = np.linspace(0, 1, len(total_errors))\n",
    "    # Calcolo dell'AUC con il nuovo asse x\n",
    "    auc = calculate_auc(x_for_auc, total_errors)\n",
    "    print(f\"Area under the curve (AUC): {auc}\")\n",
    "\n",
    "    # # Plot della curva dell'errore e area sotto la curva (AUC)\n",
    "    # plt.plot(x, total_errors, linestyle='-', label='Error curve', color='blue')\n",
    "    # # Pallini blu sui punti della curva\n",
    "    # #plt.scatter(x, total_errors, color='blue', zorder=3)\n",
    "\n",
    "    # # Area sotto la curva\n",
    "    # plt.fill_between(x, total_errors, color='skyblue', alpha=0.4)\n",
    "\n",
    "    # # Testo AUC in alto a destra\n",
    "    # plt.text(x[-1] * 0.95, max(total_errors) * 0.9, f'AUC: {auc:.2f}',\n",
    "    #      horizontalalignment='right')\n",
    "\n",
    "    # plt.xlabel('Number of superpixels inserted')  # Modifica etichetta asse X\n",
    "    # plt.ylabel('Mean Squared Error')\n",
    "    # plt.title('Insertion Metric Curve')\n",
    "    # #plt.xticks(x)  # Imposta i tick esattamente sui numeri interi (1, 2, ..., 8)\n",
    "    # plt.legend()\n",
    "    # #plt.grid(True, linestyle='--', alpha=0.6)  # Griglia più leggibile\n",
    "    # plt.show()\n",
    "    return total_errors,auc\n",
    "\n",
    "\"\"\"##### ***Deletion***\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def update_instance_removing_superpixels(current_instance, start, end, list_of_pixel, std_zero_value=-0.6486319166678826):\n",
    "    \"\"\"\n",
    "    Aggiorna l'immagine inserendo i pixel più importanti.\n",
    "\n",
    "    :param current_instance: Istanza corrente.\n",
    "    :param original_instance: Istanza originale.\n",
    "    :param index_of_superpixels: Lista contente gli indici del superpixel considerato\n",
    "    :return: Istanza aggiornata con il superpixel.\n",
    "    \"\"\"\n",
    "    new_current_instance = current_instance.copy()\n",
    "    for x,y in list_of_pixel:\n",
    "      for t in range(start,end):\n",
    "        new_current_instance[t, x, y, 0] = std_zero_value\n",
    "        new_current_instance[t, x, y, 1] = 0.0\n",
    "        new_current_instance[t, x, y, 2] = 0.0\n",
    "    return new_current_instance\n",
    "\n",
    "def deletion(models, original_instance, x3_instance, sorted_per_importance_all_superpixels_index, original_prediction):\n",
    "    \"\"\"\n",
    "    Calcola la metrica di deletion per una spiegazione data.\n",
    "\n",
    "    :param models: Lista di modelli pre-addestrati.\n",
    "    :param original_instance: Istanza originale.\n",
    "    :param x3_instance: Codifica one-hot per la previsione.\n",
    "    :param sorted_per_importance_all_superpixels_index: Lista di liste di tutti i superpixel per importanza\n",
    "    :param original_prediction: Predizione originale.\n",
    "    :return: Lista degli errori ad ogni passo di deletion.\n",
    "    \"\"\"\n",
    "\n",
    "    # Lista per memorizzare le istanze a cui aggiungo pixel mano a mano. Inizializzata con istanza originale\n",
    "    deletion_images = []\n",
    "\n",
    "    # Predizione sull'immagine iniziale (tutti i pixel a zero)\n",
    "    I_prime = copy.deepcopy(original_instance)\n",
    "\n",
    "    # Aggiungere gradualmente i pixel (per ogni frame) più importanti. Ottengo una lista con tutte le img con i pixel aggiunti in maniera graduale\n",
    "    for start,end,list_of_pixel in sorted_per_importance_all_superpixels_index:\n",
    "        I_prime = update_instance_removing_superpixels(I_prime, start, end, list_of_pixel)\n",
    "        deletion_images.append(I_prime)\n",
    "\n",
    "    # Calcolo della predizione su tutte le img a cui ho rimosso gradualmente i pixel\n",
    "    new_predictions = ensemble_predict(models, deletion_images, x3_instance)\n",
    "    # Calcolo del mse rispetto la predizione originale\n",
    "    errors = [mean_squared_error(original_prediction, masked_pred) for masked_pred in new_predictions]\n",
    "\n",
    "    initial_error = 0.0\n",
    "    print(f\"Initial Prediction with Original instance, prediction: {original_prediction}, error: {initial_error}\")\n",
    "\n",
    "    for nr_superpixel, error in enumerate(errors):\n",
    "      print(f\"Removed SuperPixel: {sorted_per_importance_all_superpixels_index[nr_superpixel]}, new prediction: {new_predictions[nr_superpixel]}, error: {error}\")\n",
    "\n",
    "    total_errors = [initial_error] + errors # Errore iniziale + errori su tutti i pixel rimossi\n",
    "\n",
    "    # Plot\n",
    "    # Nuovo asse X: numero di superpixel inseriti (1, 2, ..., 8)\n",
    "    x = np.arange(0, len(total_errors))  # Da 0 a 8 inclusi\n",
    "    #print(x)\n",
    "    x_for_auc = np.linspace(0, 1, len(total_errors))\n",
    "    # Calcolo dell'AUC con il nuovo asse x\n",
    "    auc = calculate_auc(x_for_auc, total_errors)\n",
    "    print(f\"Area under the curve (AUC): {auc}\")\n",
    "\n",
    "    # # Plot della curva dell'errore e area sotto la curva (AUC)\n",
    "    # plt.plot(x, total_errors, linestyle='-', label='Error curve', color='blue')\n",
    "    # # Area sotto la curva\n",
    "    # plt.fill_between(x, total_errors, color='lightcoral', alpha=0.4)\n",
    "    # # Testo \"Error curve\" in basso a destra\n",
    "    # plt.legend(['Error curve'], loc='lower right', bbox_to_anchor=(0.97, 0.02))\n",
    "\n",
    "    # # Testo AUC leggermente sotto la legenda\n",
    "    # plt.text(0.941, 0.13, f'AUC: {auc:.2f}',\n",
    "    #      transform=plt.gca().transAxes,\n",
    "    #      fontsize=10,\n",
    "    #      verticalalignment='bottom',\n",
    "    #      horizontalalignment='right',\n",
    "    #      bbox=dict(facecolor='white', alpha=0.6, edgecolor='grey'))\n",
    "\n",
    "    # plt.xlabel('Number of superpixels removed')\n",
    "    # plt.ylabel('Mean Squared Error')\n",
    "    # plt.title('Deletion Metric Curve')\n",
    "\n",
    "    # plt.show()\n",
    "    return total_errors,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frame_for_saliency_video(shape, coefficients, spatial_superpixels, height=5,width=8):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "   - shape: (time_steps, heigth, width, nr_channels)\n",
    "   - coefficients: coefficienti spatial_superpixel per clustet temporale\n",
    "   - spatial_superpixels: matrici 5x8 per i superpixels spaziali\n",
    "  \"\"\"\n",
    "\n",
    "  frame = np.zeros((height, width))\n",
    "\n",
    "  for i,superpixel in enumerate(spatial_superpixels):\n",
    "    frame += superpixel * coefficients[i]\n",
    "\n",
    "  return frame\n",
    "\n",
    "def find_top_indices(matrix):\n",
    "    # Flatten della matrice e ordinamento degli indici in base ai valori decrescenti\n",
    "    flat_indices = np.argsort(matrix.flatten())[::-1]\n",
    "    # Converti gli indici \"piatti\" in coordinate (x, y)\n",
    "    indices = [np.unravel_index(idx, matrix.shape) for idx in flat_indices]\n",
    "    return indices\n",
    "\n",
    "def calculate_saliency_video_insertion_deletion_errors_auc(nr_instance, abs_coefficients, temporal_superpixels, spatial_superpixels, spatial_superpixel_clusters,\n",
    "                                                           nr_temporal_superpixel, nr_spatial_superpixel,\n",
    "                                                           models, channel_prec=0, std_zero_value=-0.6486319166678826,input_size=(104,5,8,3),T=104,H=5,W=8,C=3):\n",
    "  abs_coefficients_reshape = abs_coefficients.reshape(nr_temporal_superpixel, nr_spatial_superpixel)\n",
    "\n",
    "  saliency_video = np.zeros((T, H, W))\n",
    "\n",
    "  # Frame per ogni stagione individuata\n",
    "  frames_for_t_superpixels = [create_frame_for_saliency_video(input_size, coeff, spatial_superpixels) for coeff in abs_coefficients_reshape]\n",
    "\n",
    "  for i,t_superpixel in enumerate(temporal_superpixels):\n",
    "      start, end, _ = t_superpixel\n",
    "      saliency_video[start:end+1] = frames_for_t_superpixels[i]\n",
    "\n",
    "  # ST-Superpixels ordinati per importanza\n",
    "  superpixels_importance_cluster = find_top_indices(abs_coefficients_reshape)\n",
    "  sorted_per_importance_all_superpixels_index = []\n",
    "  for nr_ts, nr_ss in superpixels_importance_cluster:\n",
    "    start,end = temporal_superpixels[nr_ts][0], temporal_superpixels[nr_ts][1] + 1\n",
    "    cluster_spatial_superpixel = spatial_superpixel_clusters[nr_ss]\n",
    "    sorted_per_importance_all_superpixels_index.append((start, end, cluster_spatial_superpixel))\n",
    "\n",
    "  # Insertion\n",
    "  instance    = copy.deepcopy(vottignasco_test_image[nr_instance])\n",
    "  x3_instance = copy.deepcopy(vottignasco_test_OHE[nr_instance])    # One-Hot encode mesi dei frame dell'istanza\n",
    "\n",
    "  all_superpixels_index = sorted_per_importance_all_superpixels_index\n",
    "  initial_blurred_instance = np.zeros((T,H,W,C))\n",
    "  initial_blurred_instance[:,:,:,channel_prec] = std_zero_value\n",
    "\n",
    "  original_prediction = ensemble_predict(models, instance, x3_instance)\n",
    "\n",
    "  errors_insertion,auc_insertion = insertion(models, instance, x3_instance, all_superpixels_index, initial_blurred_instance, original_prediction)\n",
    "\n",
    "  # Deletion\n",
    "  errors_deletion,auc_deletion = deletion(models, instance, x3_instance, all_superpixels_index, original_prediction)\n",
    "\n",
    "  return errors_insertion,auc_insertion,errors_deletion,auc_deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#results_setups_path = \"./MyDrive/Water_Resources/wr_extensions/superpixels_versions/LIME/last_try/Temporal/results/lime_temporal_insertion_deletion_results_setup_kw_80_alpha_0.pkl\"\n",
    "path_to_load_results = os.path.join(work_path, \"Water_Resources/rise-video/XAI/spatial_temporal/results/lime_shap_multiplicative_norm_zero/\")\n",
    "results_string_name  = f\"lime_shap_st_results_setup_ns_7_comp_10.pkl\"\n",
    "\n",
    "# Apri il file in modalità lettura binaria ('rb')\n",
    "with open(path_to_load_results + results_string_name, 'rb') as file:\n",
    "    lime_shap_st_results = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0030276 ,  0.10265689, -0.02457111, -0.02044141,  0.05291649,\n",
       "        0.05305451, -0.04245743, -0.07580339, -0.06894456, -0.07425273,\n",
       "        0.01262863,  0.02167514,  0.03006815,  0.03237063, -0.01814097,\n",
       "       -0.04687366, -0.04395362, -0.00689713,  0.00914542,  0.00138899,\n",
       "       -0.07734996, -0.06819287,  0.0461255 ,  0.01255203,  0.05487231,\n",
       "        0.00267578,  0.01659084, -0.03199145, -0.02128805, -0.04388248,\n",
       "       -0.12688617, -0.04007857, -0.01024403, -0.01708648, -0.0364305 ,\n",
       "       -0.01811585, -0.01398087,  0.04439715, -0.08252574, -0.01017479,\n",
       "        0.01479222,  0.04346734,  0.06472448,  0.00404835,  0.04931687,\n",
       "       -0.00191776, -0.01297372, -0.02926882,  0.00441794, -0.60417607,\n",
       "       -0.20549155, -0.1443521 , -0.36567363, -0.09242635, -0.5516351 ,\n",
       "       -0.10727446, -0.01366569,  0.05735828,  0.08363638, -0.0571634 ,\n",
       "        0.07286287,  0.07203234,  0.0464308 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lime_shap_st_results[\"shap\"][\"ns_7_comp_10\"][\"coefficients\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nr_instance in range(len(vottignasco_test_image)):\n",
    "    coefficient_i = lime_shap_st_results[\"shap\"][\"ns_7_comp_10\"][\"coefficients\"][nr_instance]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
