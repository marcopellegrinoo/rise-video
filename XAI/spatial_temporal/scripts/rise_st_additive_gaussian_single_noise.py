# -*- coding: utf-8 -*-
"""rise_st_additive_gaussian_single_noise.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B4yfAq5Q6aWSwb3zuUdIISHLK84vjD_s

### ***Cineca***
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import activations
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.models import load_model
from keras import activations
import numpy as np

"""
##### ***Data & Black-Box***

"""

# IMPORTO I DATI PER VOTTIGNASCO
import os

# Ottieni il percorso effettivo da una variabile d'ambiente
work_path = os.environ['WORK']  # Ottieni il valore della variabile d'ambiente WORK
v_test_OHE_path = os.path.join(work_path, "Water_Resources/rise-video/data/Vottignasco/Vottignasco_00425010001_test_month_OHE.npy")
v_test_image_path = os.path.join(work_path, "Water_Resources/rise-video/data/Vottignasco/Vottignasco_00425010001_test_normalized_image_sequences.npy")
v_test_target_dates_path = os.path.join(work_path, "Water_Resources/rise-video/data/Vottignasco/Vottignasco_00425010001_test_target_dates.npy")

# Carica l'array numpy dai file
vottignasco_test_OHE    = np.load(v_test_OHE_path)
vottignasco_test_image  = np.load(v_test_image_path)
vottignasco_test_dates  = np.load(v_test_target_dates_path)


print(len(vottignasco_test_dates))
print(len(vottignasco_test_image))
print(len(vottignasco_test_OHE))

# """##### ***Black Boxes***"""

import os
import tensorflow as tf
from keras.models import load_model

# Se vuoi abilitare il dropout a runtime
mc_dropout = True

# Definizione della classe personalizzata doprout_custom
class doprout_custom(tf.keras.layers.SpatialDropout1D):
    def call(self, inputs, training=None):
        if mc_dropout:
            return super().call(inputs, training=True)
        else:
            return super().call(inputs, training=False)

# Percorso della directory su Cineca
base_dir = os.path.join(os.environ['WORK'], "Water_Resources/rise-video/trained_models/seq2val/Vottignasco")
lstm_suffix = 'time_dist_LSTM'

vott_lstm_models = []

def extract_index(filename):
    """Funzione per estrarre l'indice finale dal nome del file."""
    return int(filename.split('_LSTM_')[-1].split('.')[0])

# Trova tutti i file .keras nella cartella e li aggiunge alla lista
for filename in os.listdir(base_dir):
    if lstm_suffix in filename and filename.endswith(".keras"):
        vott_lstm_models.append(os.path.join(base_dir, filename))

# Ordina i modelli in base all'indice finale
vott_lstm_models = sorted(vott_lstm_models, key=lambda x: extract_index(os.path.basename(x)))

# Lista per i modelli caricati
vott_lstm_models_loaded = []

for i, model_lstm_path in enumerate(vott_lstm_models[:10]):  # Prendo i primi 10 modelli ordinati
    #print(f"Caricamento del modello LSTM {i+1}: {model_lstm_path}")

    # Carico il modello con la classe custom
    model = load_model(model_lstm_path, custom_objects={"doprout_custom": doprout_custom})

    # Aggiungo il modello alla lista
    vott_lstm_models_loaded.append(model)

print(vott_lstm_models_loaded)

"""### ***Import & Drive***"""

# !pip install tensorflow==2.15.0 # cuDNN 8.9    CUDA 12.2 # keras 2.15.0

# !pip install rioxarray==0.15.5

# import tensorflow as tf
# from tensorflow import keras
# from tensorflow.keras import layers
# from tensorflow.keras import activations
# import sys
# from tensorflow.keras.callbacks import TensorBoard
# from tensorflow.keras.models import load_model
# from keras import activations
# import numpy as np

# # Mount Google Drive
# from google.colab import drive
# drive.mount('/gdrive')
# %cd /gdrive

"""### ***Loading from Google Drive***

##### ***Data***
"""

# # Directories

# base_path = "./MyDrive/Water_Resources/"
# data_path = base_path + "data/training_validation_test_splits"
# model_path = base_path + "trained_models/"
# modules_path = base_path + "python_modules/"
# xai_path = base_path + "XAI/"
# results_path = xai_path + "results/"

# # IMPORTO I DATI PER VOTTIGNASCO

# # Percorso ai file .npy
# v_test_OHE_path    = data_path + '/Vottignasco_00425010001_test_month_OHE.npy'
# v_test_image_path  = data_path + '/Vottignasco_00425010001_test_normalized_image_sequences.npy'
# v_test_target_dates_path = data_path + '/Vottignasco_00425010001_test_target_dates.npy'

# # Carica l'array numpy dai file
# vottignasco_test_OHE    = np.load(v_test_OHE_path)
# vottignasco_test_image  = np.load(v_test_image_path)
# vottignasco_test_dates  = np.load(v_test_target_dates_path)

"""##### ***Black Boxes***"""

# from keras.models import load_model

# # If you want to load the entire model, dropout_custom layer has to be defined:

# mc_dropout = True

# # Definizione della classe personalizzata doprout_custom
# class doprout_custom(tf.keras.layers.SpatialDropout1D):
#     def call(self, inputs, training=None):
#         if mc_dropout:
#             return super().call(inputs, training=True)
#         else:
#             return super().call(inputs, training=False)

# # Trovo i path dei modelli dell'ensemble nel mio drive. Poi li ordino in base al nr del modello.
# # VOTTIGNASCO

# import os

# base_dir = base_dir = model_path + "seq2val/Vottignasco"
# lstm_suffix = 'time_dist_LSTM'

# vott_lstm_models = []
# vott_lstm_weights = []


# def extract_index(filename):
#     """Funzione per estrarre l'indice finale dal nome del file."""
#     return int(filename.split('_')[-1].split('.')[0])

# # Trova tutti i file e li aggiunge alle rispettive liste
# for root, _, files in os.walk(base_dir):
#     for filename in files:
#         full_path = os.path.join(root, filename)
#         if lstm_suffix in filename:
#             if filename.endswith(".keras"):
#               vott_lstm_models.append(full_path)
#             else:
#               vott_lstm_weights.append(full_path)

# # Ordina i modelli in base all'indice finale
# vott_lstm_models = sorted(vott_lstm_models, key=lambda x: extract_index(os.path.basename(x)))
# vott_lstm_weights = sorted(vott_lstm_weights, key=lambda x: extract_index(os.path.basename(x)))

# # Lista dei path dei modelli e dei pesi
# vott_lstm_models_loaded = []
# racc_lstm_models_loaded = []

# for i in range(10):
#     print(f"Caricamento dei modelli LSTM {i+1}")

#     # VOTTIGNASCO
#     model_lstm_path = vott_lstm_models[i]
#     # Carico il modello CNN+LSTM
#     model = load_model(model_lstm_path, custom_objects={"doprout_custom": doprout_custom})
#     # Aggiungo il modello alla lista
#     vott_lstm_models_loaded.append(model)

# vott_lstm_models_loaded

"""### ***Spatial_Temporal-RISE***"""

import numpy as np
import matplotlib.pyplot as plt

def plot_insertion_curve(total_errors, auc, title="Insertion Metric Curve"):
    """
    Plotta la curva di metrica di insertion con l'errore medio quadratico.

    :param total_errors: Lista dei valori dell'errore per ogni frazione di pixel inseriti.
    :param auc: Valore dell'Area Under Curve (AUC) calcolato.
    :param title: Titolo del grafico (default: "Insertion Metric Curve").
    """

    # Nuovo asse X normalizzato tra 0 e 1
    x = np.linspace(0, 1, len(total_errors))

    # Plot della curva dell'errore e dell'area sotto la curva (AUC)
    plt.figure(figsize=(7, 5))
    plt.plot(x, total_errors, marker='o', linestyle='-', label='Error curve', color='blue')

    # Pallini blu sui punti della curva
    plt.scatter(x, total_errors, color='blue', zorder=3)

    # Area sotto la curva
    plt.fill_between(x, total_errors, color='skyblue', alpha=0.4)

    # Testo AUC in alto a destra
    plt.text(x[-1] * 0.95, max(total_errors) * 0.9, f'AUC: {auc:.2f}',
             horizontalalignment='right')

    # Etichette assi
    plt.xlabel('Fraction of pixels inserted')
    plt.ylabel('Mean Squared Error')

    # Titolo e legenda
    plt.title(title)
    plt.legend()

    # Mostra il grafico
    plt.show()

import numpy as np
import matplotlib.pyplot as plt

def plot_deletion_curve(total_errors, auc, title="Deletion Metric Curve"):
    """
    Plotta la curva della metrica di deletion con l'errore medio quadratico.

    :param total_errors: Lista dei valori dell'errore per ogni frazione di pixel rimossi.
    :param auc: Valore dell'Area Under Curve (AUC) calcolato.
    :param title: Titolo del grafico (default: "Deletion Metric Curve").
    """

    # Normalizzazione dell'asse X tra 0 e 1
    x = np.linspace(0, 1, len(total_errors))

    # Creazione del plot
    plt.figure(figsize=(7, 5))
    plt.plot(x, total_errors, marker='o', linestyle='-', label='Error curve', color='red')

    # Pallini rossi sui punti della curva
    plt.scatter(x, total_errors, color='red', zorder=3)

    # Area sotto la curva
    plt.fill_between(x, total_errors, color='lightcoral', alpha=0.4)

    # Testo AUC in basso a destra
    plt.text(x[-2] * 0.98, min(total_errors) * 1.1, f'AUC: {auc:.2f}',
         horizontalalignment='right')


    # Etichette degli assi
    plt.xlabel('Fraction of pixels removed')
    plt.ylabel('Mean Squared Error')

    # Titolo e legenda
    plt.title(title)
    plt.legend()

    # Mostra il grafico
    plt.show()

"""#### ***Prediction with Black-Box***"""

import tensorflow as tf

def ensemble_predict(models, images, x3_exp):
    # Se images è una lista, calcoliamo la lunghezza
    if isinstance(images, list):
        len_x3 = len(images)
    else:
        len_x3 = 1
        images = [images]  # Rendi images una lista con un solo elemento

    # Conversione in tensori
    Y_test = tf.stack([tf.convert_to_tensor(img, dtype=tf.float32) for img in images])
    Y_test_x3 = tf.tile(tf.expand_dims(tf.convert_to_tensor(x3_exp, dtype=tf.float32), axis=0), [len_x3, 1, 1])

    # Inizializza una lista per raccogliere le predizioni
    all_preds = []

    # Itera attraverso i modelli e raccogli le predizioni
    for model in models:
        preds = model.predict([Y_test, Y_test_x3], verbose=0)
        all_preds.append(preds)

    # Converte la lista di predizioni in un tensore di TensorFlow
    all_preds_tensor = tf.stack(all_preds)

    # Calcola la media lungo l'asse dei modelli (asse 0)
    mean_preds = tf.reduce_mean(all_preds_tensor, axis=0)

    return mean_preds.numpy()

"""#### ***Generation Masks (3D)***
Definisco delle funzione per ogni tipologia di rumore che stiamo testando:
* Rumore Uniforme (additivo)
* Rumore Gaussiano (additivo) con singolo centro
"""

def gaussian_perturbation(shape, center, sigma_t=50, sigma_x=1.0, sigma_y=1.0):
  time_steps, heigth, width, channels = shape
  t_center, h_center, w_center = center

  # Definizione del vettore delle medie (μ) (centro del rumore)
  mu = np.array([t_center, h_center, w_center])

  # Matrice di Covarianza tra le 3 dimensioni
  sigma = np.array([
    [sigma_t**2, 0, 0],  # Variance on time (dimensione temporale)
    [0, sigma_x**2, 0],    # Variance on height (altezza)
    [0, 0, sigma_y**2]     # Variance on width (larghezza)
  ])

  # Calcolo dell'inversa della matrice di covarianza (Σ^−1)
  sigma_inv = np.linalg.inv(sigma)

  # Generazione delle coordinate 3D
  x_coords, y_coords, z_coords = np.meshgrid(
    np.arange(time_steps), np.arange(heigth), np.arange(width), indexing='ij'
  )

  # Flattening delle coordinate per un più facile calcolo
  positions = np.vstack([x_coords.ravel(), y_coords.ravel(), z_coords.ravel()]).T

  # Calcolo della gaussiana multivariata per ogni punto
  diff = positions - mu
  exponent = -0.5 * np.sum(diff @ sigma_inv * diff, axis=1)

  # Reshape per ottenere la shape originale (104, 5, 8)
  noise_3D = np.exp(exponent).reshape(time_steps, heigth, width)

  return noise_3D

import numpy as np
from tqdm import tqdm
import copy

def generate_masks_gaussian3D(N, input_size, seed, **kwargs):
  sigma_t = kwargs.get("sigma_t", 625)  # 25^2
  sigma_x = kwargs.get("sigma_x", 1.0)
  sigma_y = kwargs.get("sigma_y", 1.0)

  nr_time_steps, heigth, width, channles = input_size
  masks = np.zeros((N, nr_time_steps, heigth, width))

  np.random.seed(seed)

  for i in tqdm(range(N), desc='Generating masks'):
    beta = np.random.choice([-1, 1]) # Non è un parametro della gaussiana. Lo uso semplicemnte per imporre il rumore o tutto positivo o tutto negativo

    t_center = np.random.randint(0, 104)
    h_center = np.random.randint(0, 5)
    w_center = np.random.randint(0, 8)
    center = (t_center, h_center, w_center)

    noise_3D = gaussian_perturbation(input_size, center, sigma_t, sigma_x, sigma_y)

    if (beta == 1):
      noise_3D = np.abs(noise_3D)  # Rende tutti i valori Positivi
    else:
      noise_3D = -np.abs(noise_3D) # Rende tutti i valori negativi

    masks[i] = noise_3D

  return masks

# sigma_t = 25
# sigma_x = 0.5
# sigma_y = 3.0

# input_size = (104,5,8,3)

# seed = 42

# N = 10

# masks = generate_masks_gaussian3D(N, input_size, seed, sigma_t=sigma_t, sigma_x=sigma_x, sigma_y=sigma_y)

# plot_sv_mean_per_season(masks[9], 0)

"""#### ***Masks Application***"""

import copy

def additive_gaussianNoise_onechannel(instance, masks, channel):
    masked = []

    # Itero su tutte le N maschere generate
    for mask in masks:
        masked_images = copy.deepcopy(instance)  # Copia profonda delle immagini originali

        # Perturba solo il canale specificato
        masked_images[..., channel] = np.add(
            masked_images[..., channel],
            mask )

        masked.append(masked_images)

    return masked

"""#### ***Saliency Video***"""

def calculate_saliency_map(preds_array, masks):
    """
    Calcola la mappa di salienza media data una serie di predizioni e maschere.

    :param preds_array: Array di predizioni (numero di maschere x dimensioni predizione).
    :param masks: Array di maschere (numero di maschere x dimensioni maschera).
    :return: Mappa di salienza media.
    """
    sal = []
    for j in range(len(masks)):
        sal_i = preds_array[j] * np.abs(masks[j])
        sal.append(sal_i.reshape(-1, 5, 8))  # Adatta la shape secondo il formato orginiale dei frame

    # Rimuovere le dimensioni extra per fare np.mean lungo axis=0. masks ha shape (N,5,8,1)
    masks_squeezed = np.squeeze(np.abs(masks))
    # Ora calcola la media lungo l'asse 0
    ev_masks = np.mean(masks_squeezed, axis=0)

    sal = (1/ev_masks) * np.mean(sal, axis=0)

    return sal

"""#### ***Spatial-Temporal-RISE: Framework***"""

def rise_spatial_temporal_explain(nr_instance, data_test_image, data_test_OHE, models, channel,
                                  N, generate_masks_fn, seed, perturb_instance_fn, **kwargs):
  print(f"############### RISE-Spatial on Instance #{nr_instance} ###############")
  instance    = copy.deepcopy(data_test_image[nr_instance])
  x3_instance = copy.deepcopy(data_test_OHE[nr_instance])

  input_size = (instance.shape[0], instance.shape[1], instance.shape[2], instance.shape[3])

  masks = generate_masks_fn(N, input_size, seed, **kwargs)
  perturbed_instances = perturb_instance_fn(instance, masks, channel)

  # Predizione su Istanza Originale
  pred_original = ensemble_predict(models, instance, x3_instance)
  # Predizioni su Istanze Perturbate
  preds_masked = ensemble_predict(models, perturbed_instances, x3_instance)

  # Differenza tra predizione originale e perturbata
  diff_pred = [abs(pred_original - pred_masked) for pred_masked in preds_masked]
  weights_array = np.concatenate(diff_pred, axis=0)

  # Calcolo della mappa di salienza
  saliency_map_i = calculate_saliency_map(weights_array, masks)
  print("############### Processo completato. Mappa di salienza generata ###############")
  return saliency_map_i

"""#### ***Evaluation Metrics***"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

def calculate_auc(x, y):
    """
    Calcola l'area sotto la curva (AUC) utilizzando il metodo del trapezio.

    :param x: Valori dell'asse x (frazione dei pixel inseriti).
    :param y: Valori dell'asse y (errori calcolati).
    :return: Area sotto la curva.
    """
    return np.trapz(y, x)

def calculate_auc_and_mean_errors(errors_all_dateset):
  mean_errors = np.mean(errors_all_dateset, axis=0)
  # Array x per il numero di superpixel inseriti
  x = np.arange(0, len(mean_errors))  # Array dinamico basato sulla lunghezza dei dati
  auc = calculate_auc(x, mean_errors)

  return auc,mean_errors

import numpy as np

# Restituisce un array like [value, [t, x, y]] con i pixel ordinati per importanza
def get_flatten_saliency_video_ordered_by_importance(saliency_video):
  flatten_saliency_video = saliency_video.flatten()  # flatten video
  indices = np.argwhere(saliency_video) # indices of pixels from original saliency video

  saliency_video_value_with_indices = [(flatten_saliency_video[i], indices[i]) for i in range(0,len(flatten_saliency_video))] # list of [saliency_value_of_pixel, [t, x, y]]

  sorted_saliency_video_for_importance_with_indices = sorted(saliency_video_value_with_indices, key=lambda x: (x[0], -x[1])) # sort by saliency_value_of_pixel

  return sorted_saliency_video_for_importance_with_indices[::-1] # return list of pixel in order of importance

import numpy as np
import matplotlib.pyplot as plt

def plot_insertion_curve(errors, title='Insertion Curve'):
    # Array x per il numero di superpixel inseriti
    x = np.arange(0, len(errors))  # Array dinamico basato sulla lunghezza dei dati
    # Creazione del errors
    plt.plot(x, errors, label='Error Curve')
    # Pallini blu sui punti della curva
    #plt.scatter(x, errors, color='blue', zorder=3)
    # Area sotto la curva (AUC)
    plt.fill_between(x, errors, color='skyblue', alpha=0.4)

    # Etichette degli assi
    plt.xlabel('Nr of pixels inserted')
    plt.ylabel('Mean Squared Error')

    # Griglia e stile
    plt.grid(True, linestyle='--', alpha=0.6)
    # Titolo e legenda
    plt.title(title)
    plt.legend()

    # Visualizzazione del grafico
    plt.show()

import numpy as np
import matplotlib.pyplot as plt

def plot_deletion_curve(errors, title='Deletion Curve'):
    # Array x per il numero di superpixel rimossi
    x = np.arange(0, len(errors))  # Array dinamico basato sulla lunghezza dei dati
    # Creazione del grafico
    plt.plot(x, errors, label='Error Curve')
    # Pallini rossi sui punti della curva
    #plt.scatter(x, errors, color='red', zorder=3)
    # Area sotto la curva (AUC)
    plt.fill_between(x, errors, color='lightcoral', alpha=0.4)

    # Etichette degli assi
    plt.xlabel('Nr of pixels removed')
    plt.ylabel('Mean Squared Error')
    # Griglia e stile
    plt.grid(True, linestyle='--', alpha=0.6)
    # Titolo e legenda
    plt.title(title)
    plt.legend()

    # Visualizzazione del grafico
    plt.show()

"""##### ***Insertion***"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

def update_image_with_important_pixel(image, initial_image, frame, x, y):
    """
    Aggiorna l'immagine inserendo i pixel più importanti.

    :param image: Immagine corrente.
    :param initial_image: Immagine originale.
    :param frame: nr di frame da inserire in image
    :param x: coordinata spaziale x del pixel
    :param y: coordinata spaziale y del pixel
    :return: Immagine aggiornata.
    """
    new_image = copy.deepcopy(image)
    new_image[frame][x,y] =+ initial_image[frame][x,y]

    return new_image

def insertion(models, original_images, x3, pixel_sorted_by_saliency_value_with_indices, initial_blurred_images, original_prediction):
    """
    Calcola la metrica di inserimento per una spiegazione data.

    :param models: Lista di modelli pre-addestrati.
    :param original_images: Immagine originale.
    :param x3: Codifica one-hot per la previsione.
    :param important_indices: Indici dei pixel in ordine di importanza.
    :param initial_blurred_images: Immagine iniziale con tutti i pixel a zero.
    :return: Lista degli errori ad ogni passo di inserimento.
    """
    T,H,W,C = original_images.shape

    # Lista per memorizzare le istanze a cui aggiungo frame mano a mano
    insertion_images = [initial_blurred_images]

    # Predizione sull'immagine iniziale (tutti i pixel a zero)
    I_prime = initial_blurred_images.copy()

    # Aggiungere gradualmente i pixel ritenuti più importanti per frame.
    for _, pixel_with_indices in pixel_sorted_by_saliency_value_with_indices:
        frame, x, y = pixel_with_indices  # extract frame (t), x and y

        I_prime = update_image_with_important_pixel(I_prime, original_images, frame, x, y)
        insertion_images.append(I_prime)

    # Calcolo le predizioni sulle istanze a cui ho aggiunto i frame in maniera graduale
    new_predictions = ensemble_predict(models, insertion_images, x3)
    # Rispetto ad ogni suddetta predizione, calcolo il MSE rispetto la pred sull'istanza originaria (come da test-set)
    errors = [mean_squared_error(original_prediction, masked_pred) for masked_pred in new_predictions[1:]]

    initial_error = mean_squared_error(original_prediction, new_predictions[0]) # mse immagine con tutti i frame blurrati
    print(f"Initial Prediction with ALL Blurred pixel, pred: {new_predictions[0]}, error: {initial_error}")
    only_inserted_frame_new_predictions = new_predictions[1:]
    # for t, error in enumerate(errors):
    #   t_f = pixel_sorted_by_saliency_value_with_indices[t][1][0]
    #   t_x = pixel_sorted_by_saliency_value_with_indices[t][1][1]
    #   t_y = pixel_sorted_by_saliency_value_with_indices[t][1][2]
    #   print(f"Insert pixel in frame {t_f} in pos ({t_x},{t_y}), new prediction: {only_inserted_frame_new_predictions[t]}, error: {error}")

    total_errors = [initial_error] + errors
    # Normalizzare la frazione di pixel inseriti
    x = [i/(T*H*W) for i in range(0, (T*H*W + 1))]
    #x = np.linspace(0, 1, len(total_errors))

    # Calcolo dell'AUC
    auc = calculate_auc(x, total_errors)
    # print(f"Area under the curve (AUC): {auc}")

    # # Plot della curva dell'errore e area sotto la curva (AUC)
    # plt.plot(x, total_errors, label='Error curve')
    # plt.fill_between(x, total_errors, color='skyblue', alpha=0.4)
    # plt.text(x[-1] * 0.95, max(total_errors) * 0.9, f'AUC: {auc:.2f}',
    #      horizontalalignment='right')  # testo a destra
    # plt.xlabel('Fraction of pixels inserted')
    # plt.ylabel('Mean Squared Error')
    # plt.title('Insertion Metric Curve')
    # plt.legend()
    # plt.show()

    return total_errors,auc

"""##### ***Deletion***"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

def update_image_by_removing_pixel(image, frame, x, y):
    """
    Aggiorna l'immagine rimuovendo i pixel più importanti.

    :param image: Immagine corrente.
    :param frame: nr di frame da inserire in image
    :param x: coordinata spaziale x del pixel
    :param y: coordinata spaziale y del pixel
    :return: Immagine aggiornata.
    """
    new_image = copy.deepcopy(image)
    new_image[frame][x,y] =+ np.zeros((1,3))

    return new_image

def deletion(models, original_images, x3, pixel_sorted_by_saliency_value_with_indices, original_prediction):
    """
    Calcola la metrica di rimozione per una spiegazione data.

    :param models: Lista di modelli pre-addestrati.
    :param original_images: Immagine originale.
    :param x3: Codifica one-hot per la previsione.
    :param important_indices: Indici dei pixel in ordine di importanza.
    :return: Lista degli errori ad ogni passo di rimozione.
    """
    T,H,W,C = original_images.shape

    # Lista per memorizzare le img a cui elimino gradualmente frames
    deletions_images = []

    # Inizializzazione
    I_prime = original_images.copy()

    # Rimuove gradualmente i pixel ritenuti più importanti per frame.
    for _, pixel_with_indices in pixel_sorted_by_saliency_value_with_indices:
        frame, x, y = pixel_with_indices  # extract frame (t), x and y

        I_prime = update_image_by_removing_pixel(I_prime, frame, x, y)
        deletions_images.append(I_prime)

    # Calcolo della predizione su tutte le img a cui rimuovo gradualmente in frames
    new_predictions = ensemble_predict(models, deletions_images, x3)
    # Calcolo del mse rispetto la predizione originale
    errors = [mean_squared_error(original_prediction, masked_pred) for masked_pred in new_predictions]

    initial_error = 0.0
    print(f"Initial Prediction with Original Images, prediction: {original_prediction}, error: {initial_error}")
    # for t, error in enumerate(errors):
    #   t_f = pixel_sorted_by_saliency_value_with_indices[t][1][0]
    #   t_x = pixel_sorted_by_saliency_value_with_indices[t][1][1]
    #   t_y = pixel_sorted_by_saliency_value_with_indices[t][1][2]
    #   print(f"Remove pixel in frame {t_f} in pos ({t_x},{t_y}), new prediction: {new_predictions[t]}, error: {error}")

    total_errors = [initial_error] + errors # Errore iniziale + errori su tutti i pixel rimossi

    x = [i/(T*H*W) for i in range(0, T*H*W+1)]

    # Calcolo dell'AUC
    auc = calculate_auc(x, total_errors)
    print(f"Area under the curve (AUC): {auc}")

    # # Plot della curva dell'errore e area sotto la curva (AUC)
    # plt.plot(x, total_errors, label='Error curve')
    # plt.fill_between(x, total_errors, color='lightcoral', alpha=0.4)
    # # Posiziona il testo AUC alla destra del titolo
    # plt.text(1.02, 1.02, f'AUC: {auc:.2f}',
    #      horizontalalignment='left',
    #      transform=plt.gca().transAxes,  # Coordinate rispetto all'asse (da 0 a 1)
    #      fontsize=11)
    # plt.xlabel('Fraction of pixels removed')
    # plt.ylabel('Mean Squared Error')
    # plt.title('Deletion Metric Curve')
    # plt.legend()
    # plt.show()

    return total_errors,auc

"""### ***Experiments***"""

channel_prec = 0      # Precipitation: canale da perturbare
channel_tmax = 1
channel_tmin = 2

shape = (104, 5, 8, 3)
T, H, W, C = shape
models      = vott_lstm_models_loaded          # Black-boxes in ensamble da spiegare

N = 5000
seed = 42

sigma_t_values = [25]
sigma_x_values = [0.5]
sigma_y_values = [3.0]

stats_mean_insertion = []
stats_mean_deletion  = []

for sigma_t in sigma_t_values:
  for sigma_x in sigma_x_values:
    for sigma_y in sigma_y_values:
      param_combination = f"N:{N}, (sigma_t:{sigma_t}, sigma_x:{sigma_x}, sigma_y:{sigma_y})"
      print(f"####################### Experiment: {param_combination} #######################")
      all_insertion_stats = []
      all_deletion_stats  = []

      for nr_instance,_ in enumerate(vottignasco_test_image):
        print(f"######### Instance #{nr_instance} with {param_combination}, generation of Saliency Video for Prec, stats for Insertion/Deletion #########")

        saliency_video_i = rise_spatial_temporal_explain(nr_instance, vottignasco_test_image, vottignasco_test_OHE, models, channel_prec,
                                                   N, generate_masks_gaussian3D, seed, additive_gaussianNoise_onechannel, sigma_t=sigma_t, sigma_x=sigma_x, sigma_y=sigma_y)

        #Insertion
        initial_blurred_instance = np.zeros((T, H, W, C))
        all_important_pixels = get_flatten_saliency_video_ordered_by_importance(saliency_video_i)
        original_instance = copy.deepcopy(vottignasco_test_image[nr_instance])
        x3_instance = copy.deepcopy(vottignasco_test_OHE[nr_instance])
        original_prediction = ensemble_predict(models, original_instance, x3_instance)
        errors_insertion,auc_insertion = insertion(models, original_instance, x3_instance, all_important_pixels, initial_blurred_instance, original_prediction)

        # Deletion
        errors_deletion,auc_deletion   = deletion(models, original_instance, x3_instance, all_important_pixels, original_prediction)

        # Aggiungi la coppia [errors_insertion, auc_insertion] alla lista
        all_insertion_stats.append([errors_insertion, auc_insertion])
        # Coppia per la Deletion
        all_deletion_stats.append([errors_deletion, auc_deletion])
        print(f"###################### End Instance #{nr_instance} ######################")

      only_errors_insertion = [errors for errors,_ in all_insertion_stats]
      auc_insertion,mean_errors_insertion = calculate_auc_and_mean_errors(only_errors_insertion)
      stats_mean_insertion.append([auc_insertion,mean_errors_insertion, param_combination])

      only_errors_deletion =  [errors for errors,_ in all_deletion_stats]
      auc_deletion,mean_errors_deletion = calculate_auc_and_mean_errors(only_errors_deletion)
      stats_mean_deletion.append([auc_deletion,mean_errors_deletion, param_combination])

      print(f"############################ ALL Dataset #############################################")


import pandas as pd

df_stats_mean_insertion = pd.DataFrame(stats_mean_insertion, columns=['AUC', 'Mean Insertion Errors for each Pixel'])
df_stats_mean_deletion  = pd.DataFrame(stats_mean_deletion,  columns=['AUC', 'Mean Deletion Errors for each Pixel'])

df_stats_mean_insertion.to_csv(os.path.join(work_path, f"Water_Resources/rise-video/XAI/spatial_temporal/results/additive_gaussian_single_noise/all_stats_mean_insertion.csv"), index=False)
df_stats_mean_deletion.to_csv(os.path.join(work_path, f"Water_Resources/rise-video/XAI/spatial_temporal/results/additive_gaussian_single_noise/all_stats_mean_deletion.csv"),   index=False)