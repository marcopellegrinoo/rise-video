# -*- coding: utf-8 -*-
"""RISE-spatial_check.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PrEkiahXelrZBC_rK2E1d6HocLFhFwKa

"""### ***Cineca***"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import activations
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.models import load_model
from keras import activations
import numpy as np

"""
##### ***Data & Black-Box***

"""

# IMPORTO I DATI PER VOTTIGNASCO
import os

# Ottieni il percorso effettivo da una variabile d'ambiente
work_path = os.environ['WORK']  # Ottieni il valore della variabile d'ambiente WORK
v_test_OHE_path = os.path.join(work_path, "Water_Resources/rise-video/data/Vottignasco/Vottignasco_00425010001_test_month_OHE.npy")
v_test_image_path = os.path.join(work_path, "Water_Resources/rise-video/data/Vottignasco/Vottignasco_00425010001_test_normalized_image_sequences.npy")
v_test_target_dates_path = os.path.join(work_path, "Water_Resources/rise-video/data/Vottignasco/Vottignasco_00425010001_test_target_dates.npy")

# Carica l'array numpy dai file
vottingasco_test_OHE    = np.load(v_test_OHE_path)
vottignasco_test_image  = np.load(v_test_image_path)
vottignasco_test_dates  = np.load(v_test_target_dates_path)


print(len(vottignasco_test_dates))
print(len(vottignasco_test_image))
print(len(vottingasco_test_OHE))

#print(vottingasco_test_OHE[0], "\n")
#print(vottignasco_test_image[0][0], "\n")

# """##### ***Black Boxes***"""

import os
import tensorflow as tf
from keras.models import load_model

# Se vuoi abilitare il dropout a runtime
mc_dropout = True

# Definizione della classe personalizzata doprout_custom
class doprout_custom(tf.keras.layers.SpatialDropout1D):
    def call(self, inputs, training=None):
        if mc_dropout:
            return super().call(inputs, training=True)
        else:
            return super().call(inputs, training=False)

# Percorso della directory su Cineca
base_dir = os.path.join(os.environ['WORK'], "Water_Resources/rise-video/trained_models/seq2val/Vottignasco")
lstm_suffix = 'time_dist_LSTM'

vott_lstm_models = []

def extract_index(filename):
    """Funzione per estrarre l'indice finale dal nome del file."""
    return int(filename.split('_LSTM_')[-1].split('.')[0])

# Trova tutti i file .keras nella cartella e li aggiunge alla lista
for filename in os.listdir(base_dir):
    if lstm_suffix in filename and filename.endswith(".keras"):
        vott_lstm_models.append(os.path.join(base_dir, filename))

# Ordina i modelli in base all'indice finale
vott_lstm_models = sorted(vott_lstm_models, key=lambda x: extract_index(os.path.basename(x)))

# Lista per i modelli caricati
vott_lstm_models_loaded = []

for i, model_lstm_path in enumerate(vott_lstm_models[:10]):  # Prendo i primi 10 modelli ordinati
    #print(f"Caricamento del modello LSTM {i+1}: {model_lstm_path}")

    # Carico il modello con la classe custom
    model = load_model(model_lstm_path, custom_objects={"doprout_custom": doprout_custom})

    # Aggiungo il modello alla lista
    vott_lstm_models_loaded.append(model)

print(vott_lstm_models_loaded)

"""### ***Spatial-RISE***

#### ***Generation Masks (2D): Uniforme***
"""

import random
import cv2

def generate_rise_masks_2d(N, H, W, h, w, p):
    """
    Genera N maschere RISE per un'immagine di dimensioni HxW.

    Parametri:
    - N: numero di maschere
    - H, W: dimensioni dell'immagine originale
    - h, w: dimensioni delle maschere a bassa risoluzione
    - p: probabilità di attivazione dei pixel nella maschera binaria iniziale

    Ritorna:
    - masks: array di shape (N, H, W) contenente le maschere normalizzate.
    """
    masks = []
    CH, CW = H // h, W // w  # Fattore di upscaling

    for _ in range(N):
        # 1. Generazione della maschera binaria iniziale (h x w)
        small_mask = np.random.rand(h, w) < p

        # 2. Upsampling bilineare alla dimensione (H + CH, W + CW)
        upsampled_mask = cv2.resize(small_mask.astype(np.float32),
                                    (W + CW, H + CH), interpolation=cv2.INTER_LINEAR)

        # 3. Crop casuale della regione H x W
        x_offset = np.random.randint(0, CW + 1)
        y_offset = np.random.randint(0, CH + 1)
        beta = random.choice([-1.0, 1.0])
        final_mask = upsampled_mask[y_offset:y_offset + H, x_offset:x_offset + W] * beta

        masks.append(final_mask)

    return np.array(masks)

import numpy as np
import copy

def perturb_instance(images, masks, channel):
    masked = []

    # Itero su tutte le N maschere generate
    for mask in masks:
        masked_images = copy.deepcopy(images)  # Copia profonda delle immagini originali

        # Perturba solo il canale specificato
        masked_images[..., channel] = np.add(
            masked_images[..., channel],
            mask
        )

        masked.append(masked_images)

    return masked

"""#### ***Prediction with Black-Box***"""

def ensemble_predict(models, images, x3_exp):
    # Se sto passando le img mascherate images è una lista. Altrimenti è np.array ed è un elemento singolo (e voglio calcolare la pred sull'img originale)
    if type(images) == list:
      len_x3 = len(images)
      #print(len_x3)
    else:
      len_x3 = 1
      images = np.expand_dims(images, axis=0)

    # Preprazione Input per l'ensemble
    Y_test = np.stack(images)
    Y_test_x3 = np.tile(x3_exp, (len_x3, 1, 1))

    # Inizializza una lista per raccogliere le predizioni
    all_preds = []

    # Itera attraverso i modelli e raccogli le predizioni
    for model in vott_lstm_models_loaded:
      preds = model.predict([Y_test, Y_test_x3], verbose=0)
      all_preds.append(preds)

    # Converte la lista di predizioni in un array di NumPy per facilitare il calcolo della media
    all_preds_array = np.array(all_preds)

    # Calcola la media delle predizioni lungo l'asse dei modelli (asse 0)
    mean_preds = np.mean(all_preds_array, axis=0)

    return mean_preds

"""#### ***Saliency-Map***"""

# Modifica della funzione per calcolare la mappa di salienza introducendo anche -> E[M] cioè il valore atteso delle Maschere

def calculate_saliency_map(weights_array, masks):
    """
    Calcola la mappa di salienza media data una serie di predizioni e maschere.

    :param weights_array: Array di predizioni (pesi delle maschere).
    :param masks: Array di maschere (numero di maschere x dimensioni maschera).
    :return: Mappa di salienza media.
    """
    sal = []
    for j in range(len(masks)):
        sal_j = weights_array[j] * np.abs(masks[j])
        sal.append(sal_j.reshape(-1, 5, 8))

    # Rimuovere le dimensioni extra per fare np.mean lungo axis=0. masks ha shape (N,5,8,1)
    masks_squeezed = np.squeeze(np.abs(masks))
    # Ora calcola la media lungo l'asse 0
    ev_masks = np.mean(masks_squeezed, axis=0)

    sal = (1/ev_masks) * np.mean(sal, axis=0)  # aggiunta della frazione 1/valore_atteso(maschere)

    return sal

"""#### ***Spatial-RISE: algorithm***"""

import numpy as np

def rise_spatial_explain(nr_instance, data_test_image, data_test_OHE, models, channel,
                          p, H,W, h,w, N, input_size):

    #print(f"############### RISE-Spatial con h,w=({h},{w}), p={p} e N={N} ############################")

    instance    = copy.deepcopy(data_test_image[nr_instance])  # istanza da spiegare
    x3_instance = copy.deepcopy(data_test_OHE[nr_instance])    # One-Hot encode mesi dei frame dell'istanza

    # Generazione delle maschere
    L = input_size
    masks = generate_rise_masks_2d(N, H, W, h, w, p)
    perturbed_instances = perturb_instance(instance, masks, channel)

    # Predizione originale
    pred_original = ensemble_predict(models, instance, x3_instance)
    preds_masked = ensemble_predict(models, perturbed_instances, x3_instance)

    # Differenza tra predizione originale e perturbata
    diff_pred = [abs(pred_original - pred_masked) for pred_masked in preds_masked]
    weights_array = np.concatenate(diff_pred, axis=0)

    # Calcolo della mappa di salienza
    saliency_map_i = calculate_saliency_map(weights_array, masks)
    #print("Processo completato. Mappa di salienza generata.")

    return saliency_map_i

"""### ***Experiments***"""

models = vott_lstm_models_loaded
channel_prec = 0

input_size = (5,8)
H,W = input_size
h,w = 2,4
p = 0.1

N = 3000

saliency_maps_vott_test = []

for nr_instance,_ in enumerate(vottignasco_test_image):
  #print(f"################### RISE-Spatial Explanation for Vottingasco Test Instance nr {nr_instance} ##################################")

  instance         = copy.deepcopy(vottignasco_test_image[nr_instance])  # istanza da spiegare
  x3_instance      = copy.deepcopy(vottingasco_test_OHE[nr_instance])    # One-Hot encode mesi dei frame dell'istanza

  sal = rise_spatial_explain(nr_instance, vottignasco_test_image, vottingasco_test_OHE, models, channel_prec, p, H,W, h,w, N, input_size)
  saliency_maps_vott_test.append(sal[0])

  #print("######################################################################################## \n")

# SAVE
array_to_save = np.array(saliency_maps_vott_test)
# Percorso completo del file di destinazione su Google Drive
file_dest_path = os.path.join(work_path, "Water_Resources/rise-video/XAI/spatial/results/saliency_maps_vott_test.npy")
# Salva l'array NumPy come file .npy
np.save(file_dest_path, array_to_save)