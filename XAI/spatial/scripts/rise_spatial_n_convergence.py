# -*- coding: utf-8 -*-
"""rise_spatial_N_convergence.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10rMfQejNufazVJGlBEyEjNd_8K650vay

### ***Cineca***
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import activations
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.models import load_model
from keras import activations
import numpy as np

"""
##### ***Data & Black-Box***

"""

# IMPORTO I DATI PER VOTTIGNASCO
import os

# Ottieni il percorso effettivo da una variabile d'ambiente
work_path = os.environ['WORK']  # Ottieni il valore della variabile d'ambiente WORK
v_test_OHE_path = os.path.join(work_path, "Water_Resources/rise-video/data/Vottignasco/Vottignasco_00425010001_test_month_OHE.npy")
v_test_image_path = os.path.join(work_path, "Water_Resources/rise-video/data/Vottignasco/Vottignasco_00425010001_test_normalized_image_sequences.npy")
v_test_target_dates_path = os.path.join(work_path, "Water_Resources/rise-video/data/Vottignasco/Vottignasco_00425010001_test_target_dates.npy")

# Carica l'array numpy dai file
vottingasco_test_OHE    = np.load(v_test_OHE_path)
vottignasco_test_image  = np.load(v_test_image_path)
vottignasco_test_dates  = np.load(v_test_target_dates_path)


print(len(vottignasco_test_dates))
print(len(vottignasco_test_image))
print(len(vottingasco_test_OHE))

#print(vottingasco_test_OHE[0], "\n")
#print(vottignasco_test_image[0][0], "\n")

# """##### ***Black Boxes***"""

import os
import tensorflow as tf
from keras.models import load_model

# Se vuoi abilitare il dropout a runtime
mc_dropout = True

# Definizione della classe personalizzata doprout_custom
class doprout_custom(tf.keras.layers.SpatialDropout1D):
    def call(self, inputs, training=None):
        if mc_dropout:
            return super().call(inputs, training=True)
        else:
            return super().call(inputs, training=False)

# Percorso della directory su Cineca
base_dir = os.path.join(os.environ['WORK'], "Water_Resources/rise-video/trained_models/seq2val/Vottignasco")
lstm_suffix = 'time_dist_LSTM'

vott_lstm_models = []

def extract_index(filename):
    """Funzione per estrarre l'indice finale dal nome del file."""
    return int(filename.split('_LSTM_')[-1].split('.')[0])

# Trova tutti i file .keras nella cartella e li aggiunge alla lista
for filename in os.listdir(base_dir):
    if lstm_suffix in filename and filename.endswith(".keras"):
        vott_lstm_models.append(os.path.join(base_dir, filename))

# Ordina i modelli in base all'indice finale
vott_lstm_models = sorted(vott_lstm_models, key=lambda x: extract_index(os.path.basename(x)))

# Lista per i modelli caricati
vott_lstm_models_loaded = []

for i, model_lstm_path in enumerate(vott_lstm_models[:10]):  # Prendo i primi 10 modelli ordinati
    #print(f"Caricamento del modello LSTM {i+1}: {model_lstm_path}")

    # Carico il modello con la classe custom
    model = load_model(model_lstm_path, custom_objects={"doprout_custom": doprout_custom})

    # Aggiungo il modello alla lista
    vott_lstm_models_loaded.append(model)

print(vott_lstm_models_loaded)

"""### ***Spatial-RISE***

#### ***Prediction with Black-Box***
"""

import tensorflow as tf

def ensemble_predict(models, images, x3_exp):
    # Se images è una lista, calcoliamo la lunghezza
    if isinstance(images, list):
        len_x3 = len(images)
    else:
        len_x3 = 1
        images = [images]  # Rendi images una lista con un solo elemento

    # Conversione in tensori
    Y_test = tf.stack([tf.convert_to_tensor(img, dtype=tf.float32) for img in images])
    Y_test_x3 = tf.tile(tf.expand_dims(tf.convert_to_tensor(x3_exp, dtype=tf.float32), axis=0), [len_x3, 1, 1])

    # Inizializza una lista per raccogliere le predizioni
    all_preds = []

    # Itera attraverso i modelli e raccogli le predizioni
    for model in models:
        preds = model.predict([Y_test, Y_test_x3], verbose=0)
        all_preds.append(preds)

    # Converte la lista di predizioni in un tensore di TensorFlow
    all_preds_tensor = tf.stack(all_preds)

    # Calcola la media lungo l'asse dei modelli (asse 0)
    mean_preds = tf.reduce_mean(all_preds_tensor, axis=0)

    return mean_preds.numpy()

"""#### ***Generation Masks (2D)***
Definisco delle funzione per ogni tipologia di rumore che stiamo testando:
* Rumore Uniforme (additivo)
* Rumore Gaussiano (additivo) con singolo centro
"""

import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm
import random

# GAUSSIAN NOISE WITH SINGLE CENTER

# Funzione per generare la perturbazione gaussiana
# MODIFICA MATTEO
def gaussian_perturbation(height, width, sigma_x, sigma_y, beta, amplitude = None):

    if amplitude == None:
      amplitude = (1/(2 * np.pi * sigma_x * sigma_y))

    x = np.arange(0, width)
    y = np.arange(0, height)
    xx, yy = np.meshgrid(x, y)

    x_p = np.random.randint(0, width)
    y_p = np.random.randint(0, height)

    perturbation = beta * amplitude * np.exp(-0.5 * ((xx - x_p)**2 / sigma_x**2 + (yy - y_p)**2 / sigma_y**2))

    return perturbation

def generate_masks_gaussian_single_center(N, input_size, seed, **kwargs):
  """
    Genera maschere con perturbazione gaussiana.

    kwargs:
    - sigma_x, sigma_y: parametri della gaussiana
    - seed: per la riproducibilità
  """
  sigma_x = kwargs.get("sigma_x", 0.75)
  sigma_y = kwargs.get("sigma_y", 0.75)

  masks = np.empty((N, *(input_size)))

  np.random.seed(seed)

  for i in tqdm(range(N), desc='Generating masks'):
    beta = np.random.choice([-1, 1])  # Fattore moltiplicativo per la perturbazione (può essere 1 o -1) -> +1 maschere positive, -1 maschere negative.
    perturbation = gaussian_perturbation(input_size[0], input_size[1], sigma_x, sigma_y, beta, amplitude=1.0)
    masks[i] = perturbation.reshape(-1,*(input_size)) # Reshape solo per visualizzare meglio la maschera

  return masks

"""#### ***Masks Application***"""

import copy

def additive_gaussianNoise_onechannel(instance, masks, channel):
    masked = []

    # Itero su tutte le N maschere generate
    for mask in masks:
        masked_images = copy.deepcopy(instance)  # Copia profonda delle immagini originali

        # Perturba solo il canale specificato
        masked_images[..., channel] = np.add(
            masked_images[..., channel],
            mask
        )

        masked.append(masked_images)

    return masked

"""#### ***Saliency Map***"""

# Modifica della funzione per calcolare la mappa di salienza introducendo anche -> E[M] cioè il valore atteso delle Maschere

def calculate_saliency_map(weights_array, masks):
    """
    Calcola la mappa di salienza media data una serie di predizioni e maschere.

    :param weights_array: Array di predizioni (pesi delle maschere).
    :param masks: Array di maschere (numero di maschere x dimensioni maschera).
    :return: Mappa di salienza media.
    """
    sal = []
    for j in range(len(masks)):
        sal_j = weights_array[j] * np.abs(masks[j])
        sal.append(sal_j.reshape(-1, 5, 8))

    # Rimuovere le dimensioni extra per fare np.mean lungo axis=0. masks ha shape (N,5,8,1)
    masks_squeezed = np.squeeze(np.abs(masks))
    # Ora calcola la media lungo l'asse 0
    ev_masks = np.mean(masks_squeezed, axis=0)

    sal = (1/ev_masks) * np.mean(sal, axis=0)  # aggiunta della frazione 1/valore_atteso(maschere)

    return sal

"""#### ***Spatial-RISE: Framework***"""

def rise_spatial_explain(nr_instance, data_test_image, data_test_OHE, models, channel,
                         N, generate_masks_fn, seed, perturb_instance_fn, **kwargs):
  print(f"############### RISE-Spatial on Instance #{nr_instance} ###############")
  instance    = copy.deepcopy(data_test_image[nr_instance])
  x3_instance = copy.deepcopy(data_test_OHE[nr_instance])

  input_size = (instance.shape[1], instance.shape[2])

  masks = generate_masks_fn(N, input_size, seed, **kwargs)
  perturbed_instances = perturb_instance_fn(instance, masks, channel)

  # Predizione su Istanza Originale
  pred_original = ensemble_predict(models, instance, x3_instance)
  # Predizioni su Istanze Perturbate
  preds_masked = ensemble_predict(models, perturbed_instances, x3_instance)

  # Differenza tra predizione originale e perturbata
  diff_pred = [abs(pred_original - pred_masked) for pred_masked in preds_masked]
  weights_array = np.concatenate(diff_pred, axis=0)

  # Calcolo della mappa di salienza
  saliency_map_i = calculate_saliency_map(weights_array, masks)
  print("############### Processo completato. Mappa di salienza generata ###############")
  return saliency_map_i

"""#### ***Evaluation Metrics***"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

def calculate_auc(x, y):
    """
    Calcola l'area sotto la curva (AUC) utilizzando il metodo del trapezio.

    :param x: Valori dell'asse x (frazione dei pixel/frame inseriti).
    :param y: Valori dell'asse y (errori calcolati).
    :return: Area sotto la curva.
    """
    return np.trapz(y, x)

import numpy as np

# Restituisce n-esimo percentile dei pixel più importanti delle mappa di salienza data in input
def get_top_n_pixels(saliency_map, n):
    # Appiattisci la mappa di salienza
    flat_saliency = saliency_map.flatten()
    # Ordina gli indici degli elementi in ordine decrescente di salienza
    sorted_indices = np.argsort(flat_saliency)[::-1]

    # Calcola il numero di colonne della mappa di salienza
    num_cols = saliency_map.shape[1]

    top_pixels = []
    for i in range(n):
        idx = sorted_indices[i]
        row, col = divmod(idx, num_cols)
        top_pixels.append((row, col))

    return top_pixels

"""##### ***Insertion***"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

def update_instance_with_pixels(current_instance, original_instance, x,y):
    """
    Aggiorna l'immagine inserendo i pixel più importanti.

    :param current_instance: Istanza corrente.
    :param original_instance: Istanza originale.
    :param x: coordinata x del pixel da inserire
    :param y: coordinata y del pixel da inserire
    :return: Istanza aggiornata con il superpixel.
    """
    new_current_instance = current_instance.copy()
    new_current_instance[:, x, y, :] = original_instance[:, x, y, :]

    return new_current_instance


def insertion(model, original_instance, x3_instance, sorted_per_importance_pixels_index, initial_blurred_instance, original_prediction):
    """
    Calcola la metrica di inserimento per una spiegazione data.

    :param model: Black-box.
    :param original_instance: Istanza originale.
    :param sorted_per_importance_pixels_index: Lista di liste di tutti i superpixel per importanza
    :param initial_blurred_images: Immagine iniziale con tutti i pixel a zero.
    :return: Lista degli errori ad ogni passo di inserimento.
    """

    # Lista per memorizzare le istanze a cui aggiungo pixel mano a mano. Inizializzata con istanza iniziale blurrata
    insertion_images = [initial_blurred_instance]

    # Predizione sull'immagine iniziale (tutti i pixel a zero)
    I_prime = copy.deepcopy(initial_blurred_instance)

    # Aggiungere gradualmente i pixel (per ogni frame) più importanti. Ottengo una lista con tutte le img con i pixel aggiunti in maniera graduale
    for x,y in sorted_per_importance_pixels_index:
        I_prime = update_instance_with_pixels(I_prime, original_instance, x,y)
        insertion_images.append(I_prime)

    insertion_images = [img.astype(np.float32) for img in insertion_images]
    # Calcolo le predizioni sulle istanze a cui ho aggiunto i pixel in maniera graduale
    new_predictions = ensemble_predict(model, insertion_images, x3_instance)
    # Rispetto ad ogni suddetta predizione, calcolo il MSE rispetto la pred sull'istanza originaria (come da test-set). Ignora la prima che è sull'img blurrata originale
    errors = [mean_squared_error(original_prediction, masked_pred) for masked_pred in new_predictions[1:]]

    initial_error = mean_squared_error(original_prediction, new_predictions[0])
    print(f"Initial Prediction with Blurred Instance. Prediction: {new_predictions[0]}, error: {initial_error}")
    only_inserted_pixel_new_predictions = new_predictions[1:]

    for nr_pixel, error in enumerate(errors):
      print(f"Inserted Pixel: {sorted_per_importance_pixels_index[nr_pixel]}. Prediction: {only_inserted_pixel_new_predictions[nr_pixel]}, error: {error}")

    total_errors = [initial_error] + errors # Errore iniziale + errori su tutti i pixel inseriti

    # # Nuovo asse X
    x = np.linspace(0, 1, len(total_errors))
    # Calcolo dell'AUC con il nuovo asse x
    auc = calculate_auc(x, total_errors)
    print(f"Area under the curve (AUC): {auc}")

    # # Plot della curva dell'errore e area sotto la curva (AUC)
    # plt.plot(x, total_errors, marker='o', linestyle='-', label='Error curve', color='blue')
    # # Pallini blu sui punti della curva
    # plt.scatter(x, total_errors, color='blue', zorder=3)

    # # Area sotto la curva
    # plt.fill_between(x, total_errors, color='skyblue', alpha=0.4)

    # # Testo AUC in alto a destra
    # plt.text(x[-1] * 0.95, max(total_errors) * 0.9, f'AUC: {auc:.2f}',
    #      horizontalalignment='right')

    # plt.xlabel('Fraction of pixel inserted')  # Modifica etichetta asse X
    # plt.ylabel('Mean Squared Error')
    # plt.title('Insertion Metric Curve')
    # #plt.xticks(x)  # Imposta i tick esattamente sui numeri interi (1, 2, ..., 8)
    # plt.legend()
    # #plt.grid(True, linestyle='--', alpha=0.6)  # Griglia più leggibile
    # plt.show()
    return total_errors,auc

"""##### ***Deletion***"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error
import copy  # Assicurati di importare copy per usare deepcopy

def update_image_by_removing_pixels(current_instance, x, y):
    """
    Aggiorna l'immagine rimuovendo i pixel x,y indicati.

    :param current_instance: istanza corrente.
    :param x: coordinata x del pixel da rimuovere
    :param y: coordinata y del pixel da rimuovere
    :return: Istanza aggiornata con x,y rimossi su tutti time-step.
    """
    new_instance = copy.deepcopy(current_instance)
    new_instance[:, x, y, :] = 0.0  # Imposta i pixel a zero
    return new_instance

def deletion(models, original_instance, x3_instance, sorted_per_importance_pixels_index, original_prediction):
    """
    Calcola la metrica di rimozione per una spiegazione data.

    :param models: Lista di modelli pre-addestrati.
    :param original_instance: Immagine originale.
    :param x3_instance: Codifica one-hot per la previsione.
    :param sorted_per_importance_pixels_index: Indici dei pixel in ordine di importanza.
    :return: Lista degli errori, auc ad ogni passo di rimozione.
    """
    # Lista per memorizzare le img a cui elimino gradualmente i pixels (per ogni time-step)
    deletion_images = []

    # Inizializzazione
    I_prime = copy.deepcopy(original_instance)

    # Aggiungere gradualmente i pixel (per ogni frame) più importanti. Ottengo una lista con tutte le img con i pixel rimossi
    for x, y in sorted_per_importance_pixels_index:
        I_prime = update_image_by_removing_pixels(I_prime, x, y)
        deletion_images.append(I_prime)

    # Calcolo della predizione su tutte le img a cui ho rimosso gradualmente i pixel
    new_predictions = ensemble_predict(models, deletion_images, x3_instance)
    # Calcolo del mse rispetto la predizione originale
    errors = [mean_squared_error(original_prediction, masked_pred) for masked_pred in new_predictions]

    initial_error = 0.0
    print(f"Initial Prediction with Original Images, prediction: {original_prediction}, error: {initial_error}")
    for nr_pixel, error in enumerate(errors):
        print(f"Removed pixel {sorted_per_importance_pixels_index[nr_pixel]}, new prediction: {new_predictions[nr_pixel]}, error: {error}")

    total_errors = [initial_error] + errors  # Errore iniziale + errori su tutti i pixel rimossi


    # Normalizzare la frazione di pixel rimossi
    x = np.linspace(0, 1, len(total_errors))
    # Calcolo dell'AUC
    auc = calculate_auc(x, total_errors)

    print(f"Area under the curve (AUC): {auc}")

    # # Plot della curva dell'errore e area sotto la curva (AUC)
    # plt.plot(x, total_errors, marker='o', linestyle='-', label='Error curve', color='blue')
    # # Pallini blu sui punti della curva
    # plt.scatter(x, total_errors, color='blue', zorder=3)

    # # Area sotto la curva
    # plt.fill_between(x, total_errors, color='lightcoral', alpha=0.4)

    # # Testo AUC in alto a destra
    # plt.text(x[-1] * 0.95, max(total_errors) * 0.9, f'AUC: {auc:.2f}', horizontalalignment='right')

    # plt.xlabel('Fraction of pixels removed')
    # plt.ylabel('Mean Squared Error')
    # plt.title('Deletion Metric Curve')
    # plt.legend()

    # # Layout pulito per evitare sovrapposizioni
    # plt.tight_layout()
    # plt.show()


    return total_errors, auc

"""### ***Experiments***

Provo la convergenza su M esperimenti in cui genero N=1000 maschere e valuto la convergenza dell'auc medio ottenuto da ogni esperimento.

Questo codice mi restituisce una lista \\
*experiments_insertion_deletion_stats* = []                 # Risultato: Lista contenente M liste di elementi [exp_evaluation_stats] \\

dove ogni *exp_evaluation_stats* contiene 105 (una per ogni istanza) quadruple (errors_insertion,errors_deletion,auc_insertion,auc_deletion)
su cui poi dovrò calcolare auc medio
"""

models = vott_lstm_models_loaded

channel_prec = 0
sigma_x = 0.75
sigma_y = 0.75

seed = 41

M = 10 # Nr esperimenti

experiments_saliency_maps = []

N = 1000

input_size = (104, 5, 8, 3)

for i in tqdm(range(0,M), desc=f'Experiments'):
  seed += 1

  saliency_maps = []
  for nr_instance,_ in enumerate(vottignasco_test_image):
    saliency_map_i = rise_spatial_explain(nr_instance, vottignasco_test_image, vottingasco_test_OHE, models, channel_prec,
                               N, generate_masks_gaussian_single_center, seed, additive_gaussianNoise_onechannel, sigma_x=0.75, sigma_y=0.75)

    saliency_maps.append(saliency_map_i)

  experiments_saliency_maps.append(saliency_maps)

# SAVE
array_to_save = np.array(experiments_saliency_maps)
# Percorso completo del file di destinazione su Google Drive
file_dest_path = os.path.join(work_path, "Water_Resources/rise-video/XAI/spatial/results/experiments_saliency_maps_gaussian_additive_single_center_sigma:0.75_N:1000_M:10.npy")
# Salva l'array NumPy come file .npy
np.save(file_dest_path, array_to_save)

experiments_insertion_deletion_stats = []                 # Risultato: Lista contenente M liste di elementi [exp_evaluation_stats]

for nr_exp, saliency_maps_exp in enumerate(experiments_saliency_maps):
  T,H,W,C = input_size
  print(f"########### Experiment nr {nr_exp +1} ###########")

  exp_all_test_set_evaluation_stats = []  # Lista di 105 quadruple (errors_insertion, errors_deletion, auc_insertion, auc_deletion)
  for nr_instance,saliency_map in enumerate(saliency_maps_exp):
    #plot_frame(saliency_map[0], cmap='Reds', title=f"Saliency Map for Instance #{nr_instance + 1}")
    initial_blurred_instance = np.zeros((T, H, W, C))

    all_important_pixels = get_top_n_pixels(saliency_map[0], H*W)

    original_instance = copy.deepcopy(vottignasco_test_image[nr_instance])
    x3_instance       = copy.deepcopy(vottingasco_test_OHE[nr_instance])
    original_prediction = ensemble_predict(models, original_instance, x3_instance)

    print(f"Experiment nr {nr_exp +1}, Instance nr {nr_instance + 1}, Original Prediction: {original_prediction}")

    errors_insertion,auc_insertion = insertion(models, original_instance, x3_instance, all_important_pixels, initial_blurred_instance, original_prediction)
    print(f"AUC: {auc_insertion}")

    errors_deletion,auc_deletion   = deletion(models, original_instance, x3_instance, all_important_pixels, original_prediction)
    print(f"AUC: {errors_deletion}")

    exp_all_test_set_evaluation_stats.append((errors_insertion,errors_deletion,auc_insertion,auc_deletion))
    print("##################################################")

  experiments_insertion_deletion_stats.append(exp_all_test_set_evaluation_stats)

  print("################################################## \n")

# SAVE
array_to_save = np.array(experiments_insertion_deletion_stats)
# Percorso completo del file di destinazione su Google Drive
file_dest_path = os.path.join(work_path, "Water_Resources/rise-video/XAI/spatial/results/experiments_insertion_deletion_stats_gaussian_additive_single_center_sigma:0.75_N:1000_M:10.npy")
# Salva l'array NumPy come file .npy
np.save(file_dest_path, array_to_save)
